_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_layer (InputLayer)     (None, 128)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 128, 300)          8329800   
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 128, 256)          691456    
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 128, 256)          590080    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 43, 256)           0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 43, 256)           0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 43, 256)           590080    
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 43, 256)           590080    
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 15, 256)           0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 15, 256)           0         
_________________________________________________________________
conv1d_5 (Conv1D)            (None, 15, 256)           590080    
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 15, 256)           590080    
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 5, 256)            0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 5, 256)            0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1280)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 256)               327936    
_________________________________________________________________
dropout_4 (Dropout)          (None, 256)               0         
_________________________________________________________________
output_layer (Dense)         (None, 3)                 771       
=================================================================
Total params: 12,300,363
Trainable params: 3,970,563
Non-trainable params: 8,329,800
_________________________________________________________________


----- Fold 1 of 10 -----
Epoch 001: val_loss improved from inf to 0.97017; runtime 0:00:05; BEST YET
Epoch 002: val_loss improved from 0.97017 to 0.82625; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.82625 to 0.71627; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.71627 to 0.56577; runtime 0:00:03; BEST YET
Epoch 005: val_loss did not improve from 0.56577; runtime 0:00:03
Epoch 006: val_loss did not improve from 0.56577; runtime 0:00:03
Epoch 007: val_loss did not improve from 0.56577; runtime 0:00:03
Fold 1 training runtime: 0:00:25

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.86      0.67      0.75       790
        HPL       0.79      0.80      0.80       564
        MWS       0.69      0.89      0.78       605

avg / total       0.79      0.77      0.77      1959

            ----- Confusion Matrix -----
True Labels  EAP  [530  82 178]
             HPL  [ 52 449  63]
             MWS  [ 34  34 537]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 2 of 10 -----
Epoch 001: val_loss improved from inf to 0.84536; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.84536 to 0.65953; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.65953 to 0.64698; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.64698 to 0.60314; runtime 0:00:03; BEST YET
Epoch 005: val_loss did not improve from 0.60314; runtime 0:00:03
Epoch 006: val_loss did not improve from 0.60314; runtime 0:00:03
Epoch 007: val_loss did not improve from 0.60314; runtime 0:00:03
Fold 2 training runtime: 0:00:25

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.81      0.81      0.81       790
        HPL       0.86      0.78      0.82       564
        MWS       0.76      0.83      0.80       605

avg / total       0.81      0.81      0.81      1959

            ----- Confusion Matrix -----
True Labels  EAP  [639  50 101]
             HPL  [ 66 442  56]
             MWS  [ 82  20 503]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 3 of 10 -----
Epoch 001: val_loss improved from inf to 0.88745; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.88745 to 0.78357; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.78357 to 0.69865; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.69865 to 0.61729; runtime 0:00:03; BEST YET
Epoch 005: val_loss improved from 0.61729 to 0.54428; runtime 0:00:03; BEST YET
Epoch 006: val_loss did not improve from 0.54428; runtime 0:00:03
Epoch 007: val_loss did not improve from 0.54428; runtime 0:00:03
Epoch 008: val_loss did not improve from 0.54428; runtime 0:00:03
Fold 3 training runtime: 0:00:28

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.80      0.80      0.80       790
        HPL       0.88      0.68      0.77       564
        MWS       0.70      0.86      0.77       605

avg / total       0.79      0.78      0.78      1959

            ----- Confusion Matrix -----
True Labels  EAP  [630  35 125]
             HPL  [ 85 381  98]
             MWS  [ 70  15 520]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 4 of 10 -----
Epoch 001: val_loss improved from inf to 0.88114; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.88114 to 0.65287; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.65287 to 0.60753; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.60753 to 0.52653; runtime 0:00:03; BEST YET
Epoch 005: val_loss improved from 0.52653 to 0.49765; runtime 0:00:03; BEST YET
Epoch 006: val_loss did not improve from 0.49765; runtime 0:00:03
Epoch 007: val_loss did not improve from 0.49765; runtime 0:00:03
Epoch 008: val_loss did not improve from 0.49765; runtime 0:00:03
Fold 4 training runtime: 0:00:28

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.79      0.82      0.81       790
        HPL       0.80      0.77      0.78       564
        MWS       0.81      0.79      0.80       605

avg / total       0.80      0.80      0.80      1959

            ----- Confusion Matrix -----
True Labels  EAP  [650  71  69]
             HPL  [ 85 434  45]
             MWS  [ 88  40 477]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 5 of 10 -----
Epoch 001: val_loss improved from inf to 0.84660; runtime 0:00:05; BEST YET
Epoch 002: val_loss improved from 0.84660 to 0.65821; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.65821 to 0.55861; runtime 0:00:03; BEST YET
Epoch 004: val_loss did not improve from 0.55861; runtime 0:00:03
Epoch 005: val_loss did not improve from 0.55861; runtime 0:00:03
Epoch 006: val_loss did not improve from 0.55861; runtime 0:00:03
Fold 5 training runtime: 0:00:22

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.82      0.75      0.78       790
        HPL       0.78      0.84      0.81       564
        MWS       0.78      0.81      0.79       604

avg / total       0.79      0.79      0.79      1958

            ----- Confusion Matrix -----
True Labels  EAP  [593  85 112]
             HPL  [ 64 471  29]
             MWS  [ 69  45 490]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 6 of 10 -----
Epoch 001: val_loss improved from inf to 0.95662; runtime 0:00:04; BEST YET
Epoch 002: val_loss did not improve from 0.95662; runtime 0:00:03
Epoch 003: val_loss improved from 0.95662 to 0.54240; runtime 0:00:03; BEST YET
Epoch 004: val_loss did not improve from 0.54240; runtime 0:00:03
Epoch 005: val_loss did not improve from 0.54240; runtime 0:00:03
Epoch 006: val_loss did not improve from 0.54240; runtime 0:00:03
Fold 6 training runtime: 0:00:21

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.94      0.36      0.52       790
        HPL       0.53      0.95      0.68       563
        MWS       0.73      0.77      0.75       604

avg / total       0.76      0.66      0.64      1957

            ----- Confusion Matrix -----
True Labels  EAP  [285 359 146]
             HPL  [  1 536  26]
             MWS  [ 16 120 468]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 7 of 10 -----
Epoch 001: val_loss improved from inf to 0.90264; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.90264 to 0.69884; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.69884 to 0.63025; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.63025 to 0.56921; runtime 0:00:03; BEST YET
Epoch 005: val_loss did not improve from 0.56921; runtime 0:00:03
Epoch 006: val_loss did not improve from 0.56921; runtime 0:00:03
Epoch 007: val_loss did not improve from 0.56921; runtime 0:00:03
Fold 7 training runtime: 0:00:25

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.79      0.77      0.78       790
        HPL       0.87      0.68      0.76       563
        MWS       0.69      0.85      0.76       604

avg / total       0.78      0.77      0.77      1957

            ----- Confusion Matrix -----
True Labels  EAP  [610  42 138]
             HPL  [ 87 383  93]
             MWS  [ 72  17 515]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 8 of 10 -----
Epoch 001: val_loss improved from inf to 0.90798; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.90798 to 0.63803; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.63803 to 0.50663; runtime 0:00:03; BEST YET
Epoch 004: val_loss did not improve from 0.50663; runtime 0:00:03
Epoch 005: val_loss did not improve from 0.50663; runtime 0:00:03
Epoch 006: val_loss did not improve from 0.50663; runtime 0:00:03
Fold 8 training runtime: 0:00:21

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.94      0.27      0.42       790
        HPL       0.47      0.97      0.64       563
        MWS       0.75      0.72      0.73       604

avg / total       0.75      0.61      0.58      1957

            ----- Confusion Matrix -----
True Labels  EAP  [211 446 133]
             HPL  [  5 547  11]
             MWS  [  9 161 434]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 9 of 10 -----
Epoch 001: val_loss improved from inf to 0.91147; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.91147 to 0.72325; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.72325 to 0.64041; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.64041 to 0.58561; runtime 0:00:03; BEST YET
Epoch 005: val_loss did not improve from 0.58561; runtime 0:00:03
Epoch 006: val_loss did not improve from 0.58561; runtime 0:00:03
Epoch 007: val_loss did not improve from 0.58561; runtime 0:00:03
Fold 9 training runtime: 0:00:24

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.62      0.95      0.75       790
        HPL       0.82      0.75      0.78       563
        MWS       0.97      0.39      0.56       604

avg / total       0.79      0.72      0.70      1957

            ----- Confusion Matrix -----
True Labels  EAP  [747  36   7]
             HPL  [142 420   1]
             MWS  [309  58 237]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 10 of 10 -----
Epoch 001: val_loss improved from inf to 0.97727; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.97727 to 0.68583; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.68583 to 0.56114; runtime 0:00:03; BEST YET
Epoch 004: val_loss did not improve from 0.56114; runtime 0:00:03
Epoch 005: val_loss did not improve from 0.56114; runtime 0:00:03
Epoch 006: val_loss did not improve from 0.56114; runtime 0:00:03
Fold 10 training runtime: 0:00:21

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.86      0.82       790
        HPL       0.90      0.68      0.77       563
        MWS       0.75      0.83      0.79       604

avg / total       0.81      0.80      0.80      1957

            ----- Confusion Matrix -----
True Labels  EAP  [677  32  81]
             HPL  [ 95 381  87]
             MWS  [ 92  10 502]
                    EAP  HPL  MWS
                  Predicted Labels
