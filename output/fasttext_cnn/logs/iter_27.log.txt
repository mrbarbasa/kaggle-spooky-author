_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_layer (InputLayer)     (None, 128)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 128, 300)          8329800   
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 128, 256)          537856    
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 128, 256)          459008    
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 64, 256)           0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 64, 256)           459008    
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 64, 256)           459008    
_________________________________________________________________
max_pooling1d_2 (MaxPooling1 (None, 32, 256)           0         
_________________________________________________________________
conv1d_5 (Conv1D)            (None, 32, 256)           459008    
_________________________________________________________________
conv1d_6 (Conv1D)            (None, 32, 256)           459008    
_________________________________________________________________
max_pooling1d_3 (MaxPooling1 (None, 16, 256)           0         
_________________________________________________________________
conv1d_7 (Conv1D)            (None, 16, 256)           459008    
_________________________________________________________________
conv1d_8 (Conv1D)            (None, 16, 256)           459008    
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 256)               0         
_________________________________________________________________
output_layer (Dense)         (None, 3)                 771       
=================================================================
Total params: 12,081,483
Trainable params: 3,751,683
Non-trainable params: 8,329,800
_________________________________________________________________


----- Fold 1 of 10 -----
Epoch 001: val_loss improved from inf to 0.90442; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.90442 to 0.56953; runtime 0:00:05; BEST YET
Epoch 003: val_loss improved from 0.56953 to 0.55599; runtime 0:00:05; BEST YET
Epoch 004: val_loss did not improve from 0.55599; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.55599; runtime 0:00:05
Epoch 006: val_loss did not improve from 0.55599; runtime 0:00:05
Fold 1 training runtime: 0:00:30

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.85      0.81       790
        HPL       0.79      0.79      0.79       564
        MWS       0.85      0.74      0.79       605

avg / total       0.80      0.80      0.80      1959

            ----- Confusion Matrix -----
True Labels  EAP  [675  61  54]
             HPL  [ 92 445  27]
             MWS  [100  59 446]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 2 of 10 -----
Epoch 001: val_loss improved from inf to 0.69908; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.69908 to 0.50975; runtime 0:00:05; BEST YET
Epoch 003: val_loss did not improve from 0.50975; runtime 0:00:05
Epoch 004: val_loss did not improve from 0.50975; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.50975; runtime 0:00:05
Fold 2 training runtime: 0:00:25

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.76      0.86      0.81       790
        HPL       0.80      0.83      0.82       564
        MWS       0.86      0.68      0.76       605

avg / total       0.80      0.80      0.80      1959

            ----- Confusion Matrix -----
True Labels  EAP  [681  66  43]
             HPL  [ 72 469  23]
             MWS  [143  50 412]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 3 of 10 -----
Epoch 001: val_loss improved from inf to 0.70156; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.70156 to 0.62772; runtime 0:00:05; BEST YET
Epoch 003: val_loss improved from 0.62772 to 0.62435; runtime 0:00:05; BEST YET
Epoch 004: val_loss did not improve from 0.62435; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.62435; runtime 0:00:05
Epoch 006: val_loss did not improve from 0.62435; runtime 0:00:05
Fold 3 training runtime: 0:00:29

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.83      0.77      0.80       790
        HPL       0.76      0.81      0.78       564
        MWS       0.77      0.81      0.79       605

avg / total       0.79      0.79      0.79      1959

            ----- Confusion Matrix -----
True Labels  EAP  [606 101  83]
             HPL  [ 46 457  61]
             MWS  [ 74  43 488]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 4 of 10 -----
Epoch 001: val_loss improved from inf to 0.78824; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.78824 to 0.52648; runtime 0:00:05; BEST YET
Epoch 003: val_loss improved from 0.52648 to 0.47888; runtime 0:00:05; BEST YET
Epoch 004: val_loss did not improve from 0.47888; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.47888; runtime 0:00:05
Epoch 006: val_loss did not improve from 0.47888; runtime 0:00:05
Fold 4 training runtime: 0:00:29

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.85      0.76      0.80       790
        HPL       0.85      0.76      0.80       564
        MWS       0.72      0.89      0.80       605

avg / total       0.81      0.80      0.80      1959

            ----- Confusion Matrix -----
True Labels  EAP  [604  56 130]
             HPL  [ 62 428  74]
             MWS  [ 48  20 537]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 5 of 10 -----
Epoch 001: val_loss improved from inf to 0.79086; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.79086 to 0.56610; runtime 0:00:05; BEST YET
Epoch 003: val_loss improved from 0.56610 to 0.52968; runtime 0:00:05; BEST YET
Epoch 004: val_loss did not improve from 0.52968; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.52968; runtime 0:00:05
Epoch 006: val_loss did not improve from 0.52968; runtime 0:00:05
Fold 5 training runtime: 0:00:30

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.84      0.74      0.79       790
        HPL       0.87      0.76      0.81       564
        MWS       0.69      0.89      0.78       604

avg / total       0.81      0.79      0.79      1958

            ----- Confusion Matrix -----
True Labels  EAP  [586  38 166]
             HPL  [ 65 428  71]
             MWS  [ 44  25 535]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 6 of 10 -----
Epoch 001: val_loss improved from inf to 0.81105; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.81105 to 0.59739; runtime 0:00:05; BEST YET
Epoch 003: val_loss improved from 0.59739 to 0.56319; runtime 0:00:05; BEST YET
Epoch 004: val_loss did not improve from 0.56319; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.56319; runtime 0:00:05
Epoch 006: val_loss did not improve from 0.56319; runtime 0:00:05
Fold 6 training runtime: 0:00:30

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.87      0.63      0.73       790
        HPL       0.73      0.87      0.79       563
        MWS       0.70      0.84      0.77       604

avg / total       0.78      0.76      0.76      1957

            ----- Confusion Matrix -----
True Labels  EAP  [499 123 168]
             HPL  [ 31 488  44]
             MWS  [ 42  56 506]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 7 of 10 -----
Epoch 001: val_loss improved from inf to 0.74151; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.74151 to 0.55770; runtime 0:00:05; BEST YET
Epoch 003: val_loss improved from 0.55770 to 0.55146; runtime 0:00:05; BEST YET
Epoch 004: val_loss did not improve from 0.55146; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.55146; runtime 0:00:05
Epoch 006: val_loss did not improve from 0.55146; runtime 0:00:05
Fold 7 training runtime: 0:00:30

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.85      0.69      0.76       790
        HPL       0.70      0.88      0.78       563
        MWS       0.79      0.79      0.79       604

avg / total       0.79      0.78      0.78      1957

            ----- Confusion Matrix -----
True Labels  EAP  [549 143  98]
             HPL  [ 42 495  26]
             MWS  [ 56  71 477]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 8 of 10 -----
Epoch 001: val_loss improved from inf to 0.73460; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.73460 to 0.50643; runtime 0:00:05; BEST YET
Epoch 003: val_loss improved from 0.50643 to 0.47675; runtime 0:00:05; BEST YET
Epoch 004: val_loss did not improve from 0.47675; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.47675; runtime 0:00:05
Epoch 006: val_loss did not improve from 0.47675; runtime 0:00:05
Fold 8 training runtime: 0:00:30

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.84      0.76      0.80       790
        HPL       0.79      0.88      0.83       563
        MWS       0.80      0.81      0.80       604

avg / total       0.81      0.81      0.81      1957

            ----- Confusion Matrix -----
True Labels  EAP  [601  91  98]
             HPL  [ 43 493  27]
             MWS  [ 69  44 491]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 9 of 10 -----
Epoch 001: val_loss improved from inf to 0.81378; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.81378 to 0.56784; runtime 0:00:05; BEST YET
Epoch 003: val_loss did not improve from 0.56784; runtime 0:00:05
Epoch 004: val_loss did not improve from 0.56784; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.56784; runtime 0:00:05
Fold 9 training runtime: 0:00:25

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.84      0.75      0.79       790
        HPL       0.72      0.86      0.78       563
        MWS       0.82      0.77      0.79       604

avg / total       0.80      0.79      0.79      1957

            ----- Confusion Matrix -----
True Labels  EAP  [592 122  76]
             HPL  [ 48 486  29]
             MWS  [ 68  71 465]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 10 of 10 -----
Epoch 001: val_loss improved from inf to 0.73579; runtime 0:00:06; BEST YET
Epoch 002: val_loss improved from 0.73579 to 0.55205; runtime 0:00:05; BEST YET
Epoch 003: val_loss improved from 0.55205 to 0.49940; runtime 0:00:05; BEST YET
Epoch 004: val_loss did not improve from 0.49940; runtime 0:00:05
Epoch 005: val_loss did not improve from 0.49940; runtime 0:00:05
Epoch 006: val_loss did not improve from 0.49940; runtime 0:00:05
Fold 10 training runtime: 0:00:30

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.83      0.84      0.83       790
        HPL       0.85      0.79      0.82       563
        MWS       0.78      0.83      0.81       604

avg / total       0.82      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [662  44  84]
             HPL  [ 67 442  54]
             MWS  [ 69  35 500]
                    EAP  HPL  MWS
                  Predicted Labels
