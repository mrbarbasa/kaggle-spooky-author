_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_layer (InputLayer)     (None, 128)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 128, 300)          8302800   
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 128, 32)           28832     
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 128, 32)           3104      
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 64, 32)            0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 64, 32)            0         
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 64, 32)            3104      
_________________________________________________________________
conv1d_4 (Conv1D)            (None, 64, 32)            3104      
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 32)                0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0         
_________________________________________________________________
output_layer (Dense)         (None, 3)                 99        
=================================================================
Total params: 8,341,043
Trainable params: 38,243
Non-trainable params: 8,302,800
_________________________________________________________________


----- Fold 1 of 10 -----
Epoch 001: val_loss improved from inf to 0.69604; runtime 0:00:03; BEST YET
Epoch 002: val_loss improved from 0.69604 to 0.64210; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.64210 to 0.58764; runtime 0:00:02; BEST YET
Epoch 004: val_loss did not improve from 0.58764; runtime 0:00:02
Epoch 005: val_loss improved from 0.58764 to 0.52832; runtime 0:00:02; BEST YET
Epoch 006: val_loss did not improve from 0.52832; runtime 0:00:02
Epoch 007: val_loss did not improve from 0.52832; runtime 0:00:02
Epoch 008: val_loss did not improve from 0.52832; runtime 0:00:02
Fold 1 training runtime: 0:00:15

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.79      0.79      0.79       790
        HPL       0.85      0.73      0.79       564
        MWS       0.75      0.85      0.80       605

avg / total       0.80      0.79      0.79      1959

            ----- Confusion Matrix -----
True Labels  EAP  [621  52 117]
             HPL  [ 95 414  55]
             MWS  [ 67  22 516]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 2 of 10 -----
Epoch 001: val_loss improved from inf to 0.68061; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.68061 to 0.62153; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.62153 to 0.56018; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.56018 to 0.53325; runtime 0:00:02; BEST YET
Epoch 005: val_loss did not improve from 0.53325; runtime 0:00:02
Epoch 006: val_loss did not improve from 0.53325; runtime 0:00:02
Epoch 007: val_loss did not improve from 0.53325; runtime 0:00:02
Fold 2 training runtime: 0:00:13

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.81      0.80       790
        HPL       0.75      0.86      0.80       564
        MWS       0.84      0.68      0.75       605

avg / total       0.79      0.79      0.78      1959

            ----- Confusion Matrix -----
True Labels  EAP  [642  86  62]
             HPL  [ 64 484  16]
             MWS  [119  72 414]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 3 of 10 -----
Epoch 001: val_loss improved from inf to 0.69662; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.69662 to 0.62118; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.62118 to 0.59617; runtime 0:00:02; BEST YET
Epoch 004: val_loss did not improve from 0.59617; runtime 0:00:02
Epoch 005: val_loss improved from 0.59617 to 0.59155; runtime 0:00:02; BEST YET
Epoch 006: val_loss did not improve from 0.59155; runtime 0:00:02
Epoch 007: val_loss improved from 0.59155 to 0.58592; runtime 0:00:02; BEST YET
Epoch 008: val_loss did not improve from 0.58592; runtime 0:00:02
Epoch 009: val_loss improved from 0.58592 to 0.58432; runtime 0:00:02; BEST YET
Epoch 010: val_loss did not improve from 0.58432; runtime 0:00:02
Epoch 011: val_loss did not improve from 0.58432; runtime 0:00:02
Epoch 012: val_loss did not improve from 0.58432; runtime 0:00:02
Fold 3 training runtime: 0:00:22

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.75      0.85      0.79       790
        HPL       0.81      0.77      0.79       564
        MWS       0.80      0.69      0.75       605

avg / total       0.78      0.78      0.78      1959

            ----- Confusion Matrix -----
True Labels  EAP  [671  55  64]
             HPL  [ 93 433  38]
             MWS  [136  49 420]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 4 of 10 -----
Epoch 001: val_loss improved from inf to 0.68806; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.68806 to 0.64835; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.64835 to 0.59447; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.59447 to 0.54709; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.54709 to 0.51699; runtime 0:00:02; BEST YET
Epoch 006: val_loss did not improve from 0.51699; runtime 0:00:02
Epoch 007: val_loss did not improve from 0.51699; runtime 0:00:02
Epoch 008: val_loss improved from 0.51699 to 0.49442; runtime 0:00:02; BEST YET
Epoch 009: val_loss did not improve from 0.49442; runtime 0:00:02
Epoch 010: val_loss did not improve from 0.49442; runtime 0:00:02
Epoch 011: val_loss did not improve from 0.49442; runtime 0:00:02
Fold 4 training runtime: 0:00:20

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.76      0.83      0.80       790
        HPL       0.77      0.82      0.80       564
        MWS       0.87      0.71      0.78       605

avg / total       0.80      0.79      0.79      1959

            ----- Confusion Matrix -----
True Labels  EAP  [658  85  47]
             HPL  [ 81 464  19]
             MWS  [126  50 429]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 5 of 10 -----
Epoch 001: val_loss improved from inf to 0.69107; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.69107 to 0.59582; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.59582 to 0.56903; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.56903 to 0.51975; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.51975 to 0.49245; runtime 0:00:02; BEST YET
Epoch 006: val_loss did not improve from 0.49245; runtime 0:00:02
Epoch 007: val_loss improved from 0.49245 to 0.49098; runtime 0:00:02; BEST YET
Epoch 008: val_loss did not improve from 0.49098; runtime 0:00:02
Epoch 009: val_loss improved from 0.49098 to 0.48834; runtime 0:00:02; BEST YET
Epoch 010: val_loss did not improve from 0.48834; runtime 0:00:02
Epoch 011: val_loss did not improve from 0.48834; runtime 0:00:02
Epoch 012: val_loss did not improve from 0.48834; runtime 0:00:02
Fold 5 training runtime: 0:00:22

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.79      0.81      0.80       790
        HPL       0.73      0.88      0.80       564
        MWS       0.87      0.67      0.75       604

avg / total       0.80      0.79      0.79      1958

            ----- Confusion Matrix -----
True Labels  EAP  [640 104  46]
             HPL  [ 49 499  16]
             MWS  [117  85 402]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 6 of 10 -----
Epoch 001: val_loss improved from inf to 0.69233; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.69233 to 0.62435; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.62435 to 0.57348; runtime 0:00:02; BEST YET
Epoch 004: val_loss did not improve from 0.57348; runtime 0:00:02
Epoch 005: val_loss improved from 0.57348 to 0.55926; runtime 0:00:02; BEST YET
Epoch 006: val_loss did not improve from 0.55926; runtime 0:00:02
Epoch 007: val_loss improved from 0.55926 to 0.55348; runtime 0:00:02; BEST YET
Epoch 008: val_loss did not improve from 0.55348; runtime 0:00:02
Epoch 009: val_loss did not improve from 0.55348; runtime 0:00:02
Epoch 010: val_loss did not improve from 0.55348; runtime 0:00:02
Fold 6 training runtime: 0:00:19

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.77      0.81      0.79       790
        HPL       0.80      0.79      0.80       563
        MWS       0.80      0.75      0.77       604

avg / total       0.79      0.79      0.79      1957

            ----- Confusion Matrix -----
True Labels  EAP  [642  67  81]
             HPL  [ 83 447  33]
             MWS  [107  45 452]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 7 of 10 -----
Epoch 001: val_loss improved from inf to 0.72955; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.72955 to 0.62435; runtime 0:00:02; BEST YET
Epoch 003: val_loss did not improve from 0.62435; runtime 0:00:02
Epoch 004: val_loss improved from 0.62435 to 0.55614; runtime 0:00:02; BEST YET
Epoch 005: val_loss did not improve from 0.55614; runtime 0:00:02
Epoch 006: val_loss did not improve from 0.55614; runtime 0:00:02
Epoch 007: val_loss did not improve from 0.55614; runtime 0:00:02
Fold 7 training runtime: 0:00:13

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.73      0.89      0.80       790
        HPL       0.87      0.71      0.78       563
        MWS       0.82      0.72      0.76       604

avg / total       0.79      0.78      0.78      1957

            ----- Confusion Matrix -----
True Labels  EAP  [702  32  56]
             HPL  [124 398  41]
             MWS  [141  29 434]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 8 of 10 -----
Epoch 001: val_loss improved from inf to 0.72676; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.72676 to 0.62953; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.62953 to 0.54467; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.54467 to 0.51979; runtime 0:00:02; BEST YET
Epoch 005: val_loss did not improve from 0.51979; runtime 0:00:02
Epoch 006: val_loss improved from 0.51979 to 0.50727; runtime 0:00:02; BEST YET
Epoch 007: val_loss did not improve from 0.50727; runtime 0:00:02
Epoch 008: val_loss did not improve from 0.50727; runtime 0:00:02
Epoch 009: val_loss did not improve from 0.50727; runtime 0:00:02
Fold 8 training runtime: 0:00:16

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.77      0.83      0.80       790
        HPL       0.85      0.74      0.79       563
        MWS       0.79      0.80      0.79       604

avg / total       0.80      0.80      0.80      1957

            ----- Confusion Matrix -----
True Labels  EAP  [658  43  89]
             HPL  [106 418  39]
             MWS  [ 94  28 482]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 9 of 10 -----
Epoch 001: val_loss improved from inf to 0.68095; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.68095 to 0.60782; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.60782 to 0.58719; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.58719 to 0.53720; runtime 0:00:02; BEST YET
Epoch 005: val_loss did not improve from 0.53720; runtime 0:00:02
Epoch 006: val_loss improved from 0.53720 to 0.52310; runtime 0:00:02; BEST YET
Epoch 007: val_loss did not improve from 0.52310; runtime 0:00:02
Epoch 008: val_loss did not improve from 0.52310; runtime 0:00:02
Epoch 009: val_loss did not improve from 0.52310; runtime 0:00:02
Fold 9 training runtime: 0:00:17

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.79      0.82      0.80       790
        HPL       0.86      0.73      0.79       563
        MWS       0.77      0.85      0.81       604

avg / total       0.81      0.80      0.80      1957

            ----- Confusion Matrix -----
True Labels  EAP  [645  46  99]
             HPL  [ 95 412  56]
             MWS  [ 73  19 512]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 10 of 10 -----
Epoch 001: val_loss improved from inf to 0.67820; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.67820 to 0.65815; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.65815 to 0.57785; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.57785 to 0.56260; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.56260 to 0.55058; runtime 0:00:02; BEST YET
Epoch 006: val_loss did not improve from 0.55058; runtime 0:00:02
Epoch 007: val_loss did not improve from 0.55058; runtime 0:00:02
Epoch 008: val_loss did not improve from 0.55058; runtime 0:00:02
Fold 10 training runtime: 0:00:15

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.77      0.84      0.80       790
        HPL       0.79      0.77      0.78       563
        MWS       0.83      0.74      0.78       604

avg / total       0.79      0.79      0.79      1957

            ----- Confusion Matrix -----
True Labels  EAP  [664  68  58]
             HPL  [ 91 435  37]
             MWS  [111  45 448]
                    EAP  HPL  MWS
                  Predicted Labels
