_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_layer (InputLayer)     (None, 128)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 128, 300)          8329800   
_________________________________________________________________
spatial_dropout1d_1 (Spatial (None, 128, 300)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, 128, 600)          1444800   
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 600)               0         
_________________________________________________________________
output_layer (Dense)         (None, 3)                 1803      
=================================================================
Total params: 9,776,403
Trainable params: 1,446,603
Non-trainable params: 8,329,800
_________________________________________________________________


----- Fold 1 of 10 -----
Epoch 001: val_loss improved from inf to 0.63958; runtime 0:00:07; BEST YET
Epoch 002: val_loss improved from 0.63958 to 0.57625; runtime 0:00:06; BEST YET
Epoch 003: val_loss improved from 0.57625 to 0.51133; runtime 0:00:06; BEST YET
Epoch 004: val_loss improved from 0.51133 to 0.48144; runtime 0:00:06; BEST YET
Epoch 005: val_loss did not improve from 0.48144; runtime 0:00:06
Epoch 006: val_loss improved from 0.48144 to 0.46608; runtime 0:00:06; BEST YET
Epoch 007: val_loss improved from 0.46608 to 0.41281; runtime 0:00:06; BEST YET
Epoch 008: val_loss did not improve from 0.41281; runtime 0:00:06
Epoch 009: val_loss did not improve from 0.41281; runtime 0:00:06
Epoch 010: val_loss improved from 0.41281 to 0.40152; runtime 0:00:06; BEST YET
Epoch 011: val_loss did not improve from 0.40152; runtime 0:00:06
Epoch 012: val_loss did not improve from 0.40152; runtime 0:00:06
Epoch 013: val_loss improved from 0.40152 to 0.39803; runtime 0:00:06; BEST YET
Epoch 014: val_loss did not improve from 0.39803; runtime 0:00:06
Epoch 015: val_loss did not improve from 0.39803; runtime 0:00:06
Epoch 016: val_loss did not improve from 0.39803; runtime 0:00:06
Fold 1 training runtime: 0:01:44

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.80      0.89      0.84       790
        HPL       0.95      0.74      0.83       564
        MWS       0.83      0.88      0.86       605

avg / total       0.85      0.84      0.84      1959

            ----- Confusion Matrix -----
True Labels  EAP  [702  16  72]
             HPL  [111 417  36]
             MWS  [ 66   6 533]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 2 of 10 -----
Epoch 001: val_loss improved from inf to 0.62334; runtime 0:00:07; BEST YET
Epoch 002: val_loss improved from 0.62334 to 0.53923; runtime 0:00:06; BEST YET
Epoch 003: val_loss improved from 0.53923 to 0.51066; runtime 0:00:06; BEST YET
Epoch 004: val_loss improved from 0.51066 to 0.45431; runtime 0:00:06; BEST YET
Epoch 005: val_loss improved from 0.45431 to 0.41681; runtime 0:00:06; BEST YET
Epoch 006: val_loss improved from 0.41681 to 0.40033; runtime 0:00:06; BEST YET
Epoch 007: val_loss improved from 0.40033 to 0.38060; runtime 0:00:06; BEST YET
Epoch 008: val_loss improved from 0.38060 to 0.37003; runtime 0:00:06; BEST YET
Epoch 009: val_loss improved from 0.37003 to 0.35602; runtime 0:00:06; BEST YET
Epoch 010: val_loss did not improve from 0.35602; runtime 0:00:06
Epoch 011: val_loss did not improve from 0.35602; runtime 0:00:06
Epoch 012: val_loss did not improve from 0.35602; runtime 0:00:06
Fold 2 training runtime: 0:01:18

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.93      0.85       790
        HPL       0.94      0.80      0.87       564
        MWS       0.89      0.79      0.84       605

avg / total       0.86      0.85      0.85      1959

            ----- Confusion Matrix -----
True Labels  EAP  [733  19  38]
             HPL  [ 92 452  20]
             MWS  [118  10 477]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 3 of 10 -----
Epoch 001: val_loss improved from inf to 0.64947; runtime 0:00:07; BEST YET
Epoch 002: val_loss did not improve from 0.64947; runtime 0:00:06
Epoch 003: val_loss improved from 0.64947 to 0.51751; runtime 0:00:06; BEST YET
Epoch 004: val_loss improved from 0.51751 to 0.47618; runtime 0:00:06; BEST YET
Epoch 005: val_loss improved from 0.47618 to 0.47560; runtime 0:00:06; BEST YET
Epoch 006: val_loss improved from 0.47560 to 0.46177; runtime 0:00:06; BEST YET
Epoch 007: val_loss improved from 0.46177 to 0.43974; runtime 0:00:06; BEST YET
Epoch 008: val_loss did not improve from 0.43974; runtime 0:00:06
Epoch 009: val_loss improved from 0.43974 to 0.42542; runtime 0:00:06; BEST YET
Epoch 010: val_loss improved from 0.42542 to 0.42518; runtime 0:00:06; BEST YET
Epoch 011: val_loss improved from 0.42518 to 0.41341; runtime 0:00:06; BEST YET
Epoch 012: val_loss improved from 0.41341 to 0.40743; runtime 0:00:06; BEST YET
Epoch 013: val_loss did not improve from 0.40743; runtime 0:00:06
Epoch 014: val_loss did not improve from 0.40743; runtime 0:00:06
Epoch 015: val_loss did not improve from 0.40743; runtime 0:00:06
Fold 3 training runtime: 0:01:37

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.83      0.85      0.84       790
        HPL       0.89      0.79      0.84       564
        MWS       0.80      0.86      0.83       605

avg / total       0.84      0.84      0.84      1959

            ----- Confusion Matrix -----
True Labels  EAP  [675  37  78]
             HPL  [ 68 443  53]
             MWS  [ 66  17 522]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 4 of 10 -----
Epoch 001: val_loss improved from inf to 0.67535; runtime 0:00:07; BEST YET
Epoch 002: val_loss improved from 0.67535 to 0.54910; runtime 0:00:06; BEST YET
Epoch 003: val_loss improved from 0.54910 to 0.50398; runtime 0:00:06; BEST YET
Epoch 004: val_loss improved from 0.50398 to 0.49580; runtime 0:00:06; BEST YET
Epoch 005: val_loss improved from 0.49580 to 0.44248; runtime 0:00:06; BEST YET
Epoch 006: val_loss improved from 0.44248 to 0.42828; runtime 0:00:06; BEST YET
Epoch 007: val_loss improved from 0.42828 to 0.42533; runtime 0:00:06; BEST YET
Epoch 008: val_loss improved from 0.42533 to 0.39987; runtime 0:00:06; BEST YET
Epoch 009: val_loss did not improve from 0.39987; runtime 0:00:06
Epoch 010: val_loss did not improve from 0.39987; runtime 0:00:06
Epoch 011: val_loss improved from 0.39987 to 0.38153; runtime 0:00:06; BEST YET
Epoch 012: val_loss did not improve from 0.38153; runtime 0:00:06
Epoch 013: val_loss improved from 0.38153 to 0.37341; runtime 0:00:06; BEST YET
Epoch 014: val_loss did not improve from 0.37341; runtime 0:00:06
Epoch 015: val_loss did not improve from 0.37341; runtime 0:00:06
Epoch 016: val_loss did not improve from 0.37341; runtime 0:00:06
Fold 4 training runtime: 0:01:44

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.81      0.87      0.84       790
        HPL       0.91      0.76      0.83       564
        MWS       0.82      0.87      0.85       605

avg / total       0.84      0.84      0.84      1959

            ----- Confusion Matrix -----
True Labels  EAP  [689  36  65]
             HPL  [ 87 430  47]
             MWS  [ 71   9 525]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 5 of 10 -----
Epoch 001: val_loss improved from inf to 0.60125; runtime 0:00:07; BEST YET
Epoch 002: val_loss improved from 0.60125 to 0.52878; runtime 0:00:06; BEST YET
Epoch 003: val_loss improved from 0.52878 to 0.48079; runtime 0:00:06; BEST YET
Epoch 004: val_loss improved from 0.48079 to 0.44640; runtime 0:00:06; BEST YET
Epoch 005: val_loss did not improve from 0.44640; runtime 0:00:06
Epoch 006: val_loss improved from 0.44640 to 0.40127; runtime 0:00:06; BEST YET
Epoch 007: val_loss improved from 0.40127 to 0.38861; runtime 0:00:06; BEST YET
Epoch 008: val_loss did not improve from 0.38861; runtime 0:00:06
Epoch 009: val_loss did not improve from 0.38861; runtime 0:00:06
Epoch 010: val_loss improved from 0.38861 to 0.38625; runtime 0:00:06; BEST YET
Epoch 011: val_loss improved from 0.38625 to 0.37410; runtime 0:00:06; BEST YET
Epoch 012: val_loss did not improve from 0.37410; runtime 0:00:06
Epoch 013: val_loss did not improve from 0.37410; runtime 0:00:06
Epoch 014: val_loss did not improve from 0.37410; runtime 0:00:06
Fold 5 training runtime: 0:01:31

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.87      0.81      0.84       790
        HPL       0.85      0.88      0.86       564
        MWS       0.83      0.86      0.84       604

avg / total       0.85      0.85      0.85      1958

            ----- Confusion Matrix -----
True Labels  EAP  [641  58  91]
             HPL  [ 48 497  19]
             MWS  [ 50  33 521]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 6 of 10 -----
Epoch 001: val_loss improved from inf to 0.63689; runtime 0:00:07; BEST YET
Epoch 002: val_loss improved from 0.63689 to 0.54251; runtime 0:00:06; BEST YET
Epoch 003: val_loss improved from 0.54251 to 0.51485; runtime 0:00:06; BEST YET
Epoch 004: val_loss improved from 0.51485 to 0.47492; runtime 0:00:06; BEST YET
Epoch 005: val_loss improved from 0.47492 to 0.45507; runtime 0:00:06; BEST YET
Epoch 006: val_loss improved from 0.45507 to 0.42795; runtime 0:00:06; BEST YET
Epoch 007: val_loss improved from 0.42795 to 0.41686; runtime 0:00:06; BEST YET
Epoch 008: val_loss did not improve from 0.41686; runtime 0:00:06
Epoch 009: val_loss improved from 0.41686 to 0.40922; runtime 0:00:06; BEST YET
Epoch 010: val_loss did not improve from 0.40922; runtime 0:00:06
Epoch 011: val_loss did not improve from 0.40922; runtime 0:00:06
Epoch 012: val_loss did not improve from 0.40922; runtime 0:00:06
Fold 6 training runtime: 0:01:18

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.90      0.84       790
        HPL       0.94      0.73      0.82       563
        MWS       0.83      0.84      0.83       604

avg / total       0.84      0.83      0.83      1957

            ----- Confusion Matrix -----
True Labels  EAP  [713  18  59]
             HPL  [110 411  42]
             MWS  [ 90   9 505]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 7 of 10 -----
Epoch 001: val_loss improved from inf to 0.65211; runtime 0:00:07; BEST YET
Epoch 002: val_loss improved from 0.65211 to 0.58012; runtime 0:00:06; BEST YET
Epoch 003: val_loss improved from 0.58012 to 0.53213; runtime 0:00:06; BEST YET
Epoch 004: val_loss improved from 0.53213 to 0.49529; runtime 0:00:06; BEST YET
Epoch 005: val_loss improved from 0.49529 to 0.46845; runtime 0:00:06; BEST YET
Epoch 006: val_loss improved from 0.46845 to 0.46041; runtime 0:00:06; BEST YET
Epoch 007: val_loss improved from 0.46041 to 0.43215; runtime 0:00:06; BEST YET
Epoch 008: val_loss improved from 0.43215 to 0.42608; runtime 0:00:06; BEST YET
Epoch 009: val_loss did not improve from 0.42608; runtime 0:00:06
Epoch 010: val_loss did not improve from 0.42608; runtime 0:00:06
Epoch 011: val_loss did not improve from 0.42608; runtime 0:00:06
Fold 7 training runtime: 0:01:12

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.89      0.83       790
        HPL       0.93      0.73      0.81       563
        MWS       0.81      0.82      0.82       604

avg / total       0.83      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [700  20  70]
             HPL  [104 409  50]
             MWS  [ 93  13 498]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 8 of 10 -----
Epoch 001: val_loss improved from inf to 0.60507; runtime 0:00:07; BEST YET
Epoch 002: val_loss improved from 0.60507 to 0.53507; runtime 0:00:06; BEST YET
Epoch 003: val_loss improved from 0.53507 to 0.49355; runtime 0:00:06; BEST YET
Epoch 004: val_loss improved from 0.49355 to 0.45431; runtime 0:00:06; BEST YET
Epoch 005: val_loss improved from 0.45431 to 0.42505; runtime 0:00:06; BEST YET
Epoch 006: val_loss did not improve from 0.42505; runtime 0:00:06
Epoch 007: val_loss improved from 0.42505 to 0.41201; runtime 0:00:06; BEST YET
Epoch 008: val_loss improved from 0.41201 to 0.38143; runtime 0:00:06; BEST YET
Epoch 009: val_loss improved from 0.38143 to 0.37315; runtime 0:00:06; BEST YET
Epoch 010: val_loss improved from 0.37315 to 0.36926; runtime 0:00:06; BEST YET
Epoch 011: val_loss did not improve from 0.36926; runtime 0:00:06
Epoch 012: val_loss did not improve from 0.36926; runtime 0:00:06
Epoch 013: val_loss did not improve from 0.36926; runtime 0:00:06
Fold 8 training runtime: 0:01:24

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.85      0.87      0.86       790
        HPL       0.90      0.83      0.86       563
        MWS       0.83      0.85      0.84       604

avg / total       0.86      0.85      0.85      1957

            ----- Confusion Matrix -----
True Labels  EAP  [687  34  69]
             HPL  [ 55 469  39]
             MWS  [ 68  20 516]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 9 of 10 -----
Epoch 001: val_loss improved from inf to 0.62425; runtime 0:00:07; BEST YET
Epoch 002: val_loss improved from 0.62425 to 0.55260; runtime 0:00:06; BEST YET
Epoch 003: val_loss did not improve from 0.55260; runtime 0:00:06
Epoch 004: val_loss improved from 0.55260 to 0.51281; runtime 0:00:06; BEST YET
Epoch 005: val_loss improved from 0.51281 to 0.46165; runtime 0:00:06; BEST YET
Epoch 006: val_loss improved from 0.46165 to 0.45766; runtime 0:00:06; BEST YET
Epoch 007: val_loss improved from 0.45766 to 0.45624; runtime 0:00:06; BEST YET
Epoch 008: val_loss improved from 0.45624 to 0.42676; runtime 0:00:06; BEST YET
Epoch 009: val_loss improved from 0.42676 to 0.39492; runtime 0:00:06; BEST YET
Epoch 010: val_loss did not improve from 0.39492; runtime 0:00:06
Epoch 011: val_loss did not improve from 0.39492; runtime 0:00:06
Epoch 012: val_loss did not improve from 0.39492; runtime 0:00:06
Fold 9 training runtime: 0:01:18

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.80      0.89      0.85       790
        HPL       0.95      0.74      0.83       563
        MWS       0.82      0.87      0.84       604

avg / total       0.85      0.84      0.84      1957

            ----- Confusion Matrix -----
True Labels  EAP  [707  16  67]
             HPL  [101 414  48]
             MWS  [ 73   7 524]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 10 of 10 -----
Epoch 001: val_loss improved from inf to 0.63083; runtime 0:00:07; BEST YET
Epoch 002: val_loss improved from 0.63083 to 0.55680; runtime 0:00:06; BEST YET
Epoch 003: val_loss improved from 0.55680 to 0.49283; runtime 0:00:06; BEST YET
Epoch 004: val_loss improved from 0.49283 to 0.46000; runtime 0:00:06; BEST YET
Epoch 005: val_loss improved from 0.46000 to 0.45407; runtime 0:00:06; BEST YET
Epoch 006: val_loss improved from 0.45407 to 0.41226; runtime 0:00:06; BEST YET
Epoch 007: val_loss improved from 0.41226 to 0.40086; runtime 0:00:06; BEST YET
Epoch 008: val_loss improved from 0.40086 to 0.39637; runtime 0:00:06; BEST YET
Epoch 009: val_loss did not improve from 0.39637; runtime 0:00:06
Epoch 010: val_loss did not improve from 0.39637; runtime 0:00:06
Epoch 011: val_loss improved from 0.39637 to 0.37351; runtime 0:00:06; BEST YET
Epoch 012: val_loss improved from 0.37351 to 0.37313; runtime 0:00:06; BEST YET
Epoch 013: val_loss did not improve from 0.37313; runtime 0:00:06
Epoch 014: val_loss did not improve from 0.37313; runtime 0:00:06
Epoch 015: val_loss improved from 0.37313 to 0.37048; runtime 0:00:06; BEST YET
Epoch 016: val_loss did not improve from 0.37048; runtime 0:00:06
Epoch 017: val_loss did not improve from 0.37048; runtime 0:00:06
Epoch 018: val_loss did not improve from 0.37048; runtime 0:00:06
Fold 10 training runtime: 0:01:57

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.82      0.88      0.85       790
        HPL       0.89      0.82      0.85       563
        MWS       0.84      0.82      0.83       604

avg / total       0.85      0.84      0.84      1957

            ----- Confusion Matrix -----
True Labels  EAP  [698  32  60]
             HPL  [ 68 459  36]
             MWS  [ 87  22 495]
                    EAP  HPL  MWS
                  Predicted Labels
