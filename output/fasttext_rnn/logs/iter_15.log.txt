__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_layer (InputLayer)        (None, 128)          0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 128, 300)     8329800     input_layer[0][0]                
__________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDro (None, 128, 300)     0           embedding_1[0][0]                
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128, 512)     1142784     spatial_dropout1d_1[0][0]        
__________________________________________________________________________________________________
global_average_pooling1d_1 (Glo (None, 512)          0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 512)          0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 1024)         0           global_average_pooling1d_1[0][0] 
                                                                 global_max_pooling1d_1[0][0]     
__________________________________________________________________________________________________
output_layer (Dense)            (None, 3)            3075        concatenate_1[0][0]              
==================================================================================================
Total params: 9,475,659
Trainable params: 1,145,859
Non-trainable params: 8,329,800
__________________________________________________________________________________________________


----- Fold 1 of 10 -----
Epoch 001: val_loss improved from inf to 0.69674; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.69674 to 0.61407; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.61407 to 0.58312; runtime 0:00:04; BEST YET
Epoch 004: val_loss improved from 0.58312 to 0.57626; runtime 0:00:04; BEST YET
Epoch 005: val_loss improved from 0.57626 to 0.55056; runtime 0:00:03; BEST YET
Epoch 006: val_loss improved from 0.55056 to 0.53986; runtime 0:00:04; BEST YET
Epoch 007: val_loss improved from 0.53986 to 0.53336; runtime 0:00:04; BEST YET
Epoch 008: val_loss improved from 0.53336 to 0.50201; runtime 0:00:04; BEST YET
Epoch 009: val_loss improved from 0.50201 to 0.49895; runtime 0:00:04; BEST YET
Epoch 010: val_loss improved from 0.49895 to 0.48449; runtime 0:00:04; BEST YET
Epoch 011: val_loss improved from 0.48449 to 0.46914; runtime 0:00:03; BEST YET
Epoch 012: val_loss improved from 0.46914 to 0.46073; runtime 0:00:04; BEST YET
Epoch 013: val_loss improved from 0.46073 to 0.45131; runtime 0:00:04; BEST YET
Epoch 014: val_loss improved from 0.45131 to 0.44296; runtime 0:00:03; BEST YET
Epoch 015: val_loss did not improve from 0.44296; runtime 0:00:03
Epoch 016: val_loss improved from 0.44296 to 0.43579; runtime 0:00:03; BEST YET
Epoch 017: val_loss did not improve from 0.43579; runtime 0:00:03
Epoch 018: val_loss improved from 0.43579 to 0.41699; runtime 0:00:03; BEST YET
Epoch 019: val_loss did not improve from 0.41699; runtime 0:00:03
Epoch 020: val_loss did not improve from 0.41699; runtime 0:00:03
Epoch 021: val_loss did not improve from 0.41699; runtime 0:00:03
Fold 1 training runtime: 0:01:14

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.89      0.83       790
        HPL       0.91      0.75      0.82       564
        MWS       0.85      0.82      0.84       605

avg / total       0.84      0.83      0.83      1959

            ----- Confusion Matrix -----
True Labels  EAP  [707  30  53]
             HPL  [110 422  32]
             MWS  [ 93  14 498]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 2 of 10 -----
Epoch 001: val_loss improved from inf to 0.66494; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.66494 to 0.59925; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.59925 to 0.57468; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.57468 to 0.54072; runtime 0:00:03; BEST YET
Epoch 005: val_loss did not improve from 0.54072; runtime 0:00:03
Epoch 006: val_loss improved from 0.54072 to 0.51849; runtime 0:00:03; BEST YET
Epoch 007: val_loss improved from 0.51849 to 0.48907; runtime 0:00:04; BEST YET
Epoch 008: val_loss improved from 0.48907 to 0.47686; runtime 0:00:03; BEST YET
Epoch 009: val_loss improved from 0.47686 to 0.45611; runtime 0:00:03; BEST YET
Epoch 010: val_loss did not improve from 0.45611; runtime 0:00:03
Epoch 011: val_loss improved from 0.45611 to 0.43536; runtime 0:00:03; BEST YET
Epoch 012: val_loss improved from 0.43536 to 0.42548; runtime 0:00:03; BEST YET
Epoch 013: val_loss improved from 0.42548 to 0.41007; runtime 0:00:03; BEST YET
Epoch 014: val_loss improved from 0.41007 to 0.40556; runtime 0:00:03; BEST YET
Epoch 015: val_loss improved from 0.40556 to 0.39242; runtime 0:00:03; BEST YET
Epoch 016: val_loss did not improve from 0.39242; runtime 0:00:03
Epoch 017: val_loss did not improve from 0.39242; runtime 0:00:03
Epoch 018: val_loss did not improve from 0.39242; runtime 0:00:03
Fold 2 training runtime: 0:01:03

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.80      0.90      0.85       790
        HPL       0.89      0.82      0.85       564
        MWS       0.86      0.78      0.82       605

avg / total       0.84      0.84      0.84      1959

            ----- Confusion Matrix -----
True Labels  EAP  [710  33  47]
             HPL  [ 75 462  27]
             MWS  [105  26 474]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 3 of 10 -----
Epoch 001: val_loss improved from inf to 0.66904; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.66904 to 0.61239; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.61239 to 0.59382; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.59382 to 0.58232; runtime 0:00:03; BEST YET
Epoch 005: val_loss improved from 0.58232 to 0.55223; runtime 0:00:03; BEST YET
Epoch 006: val_loss improved from 0.55223 to 0.53423; runtime 0:00:03; BEST YET
Epoch 007: val_loss improved from 0.53423 to 0.53274; runtime 0:00:03; BEST YET
Epoch 008: val_loss improved from 0.53274 to 0.50609; runtime 0:00:03; BEST YET
Epoch 009: val_loss improved from 0.50609 to 0.49564; runtime 0:00:03; BEST YET
Epoch 010: val_loss did not improve from 0.49564; runtime 0:00:03
Epoch 011: val_loss did not improve from 0.49564; runtime 0:00:03
Epoch 012: val_loss improved from 0.49564 to 0.47167; runtime 0:00:03; BEST YET
Epoch 013: val_loss improved from 0.47167 to 0.46525; runtime 0:00:03; BEST YET
Epoch 014: val_loss improved from 0.46525 to 0.44046; runtime 0:00:03; BEST YET
Epoch 015: val_loss did not improve from 0.44046; runtime 0:00:03
Epoch 016: val_loss did not improve from 0.44046; runtime 0:00:03
Epoch 017: val_loss did not improve from 0.44046; runtime 0:00:03
Fold 3 training runtime: 0:01:00

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.76      0.92      0.83       790
        HPL       0.87      0.77      0.82       564
        MWS       0.90      0.75      0.81       605

avg / total       0.83      0.82      0.82      1959

            ----- Confusion Matrix -----
True Labels  EAP  [726  36  28]
             HPL  [107 432  25]
             MWS  [127  26 452]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 4 of 10 -----
Epoch 001: val_loss improved from inf to 0.65381; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.65381 to 0.59716; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.59716 to 0.58798; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.58798 to 0.56927; runtime 0:00:03; BEST YET
Epoch 005: val_loss improved from 0.56927 to 0.52844; runtime 0:00:03; BEST YET
Epoch 006: val_loss improved from 0.52844 to 0.50926; runtime 0:00:03; BEST YET
Epoch 007: val_loss improved from 0.50926 to 0.49936; runtime 0:00:03; BEST YET
Epoch 008: val_loss improved from 0.49936 to 0.49458; runtime 0:00:03; BEST YET
Epoch 009: val_loss improved from 0.49458 to 0.46298; runtime 0:00:04; BEST YET
Epoch 010: val_loss did not improve from 0.46298; runtime 0:00:03
Epoch 011: val_loss improved from 0.46298 to 0.45097; runtime 0:00:03; BEST YET
Epoch 012: val_loss improved from 0.45097 to 0.43497; runtime 0:00:03; BEST YET
Epoch 013: val_loss did not improve from 0.43497; runtime 0:00:03
Epoch 014: val_loss improved from 0.43497 to 0.42236; runtime 0:00:03; BEST YET
Epoch 015: val_loss did not improve from 0.42236; runtime 0:00:04
Epoch 016: val_loss improved from 0.42236 to 0.40194; runtime 0:00:03; BEST YET
Epoch 017: val_loss did not improve from 0.40194; runtime 0:00:03
Epoch 018: val_loss improved from 0.40194 to 0.39821; runtime 0:00:03; BEST YET
Epoch 019: val_loss did not improve from 0.39821; runtime 0:00:03
Epoch 020: val_loss did not improve from 0.39821; runtime 0:00:03
Epoch 021: val_loss did not improve from 0.39821; runtime 0:00:03
Fold 4 training runtime: 0:01:14

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.80      0.86      0.83       790
        HPL       0.90      0.71      0.79       564
        MWS       0.80      0.88      0.84       605

avg / total       0.83      0.82      0.82      1959

            ----- Confusion Matrix -----
True Labels  EAP  [683  34  73]
             HPL  [105 398  61]
             MWS  [ 61   9 535]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 5 of 10 -----
Epoch 001: val_loss improved from inf to 0.67359; runtime 0:00:05; BEST YET
Epoch 002: val_loss improved from 0.67359 to 0.59758; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.59758 to 0.56564; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.56564 to 0.53473; runtime 0:00:03; BEST YET
Epoch 005: val_loss improved from 0.53473 to 0.53363; runtime 0:00:03; BEST YET
Epoch 006: val_loss improved from 0.53363 to 0.51897; runtime 0:00:03; BEST YET
Epoch 007: val_loss improved from 0.51897 to 0.48967; runtime 0:00:03; BEST YET
Epoch 008: val_loss improved from 0.48967 to 0.47778; runtime 0:00:03; BEST YET
Epoch 009: val_loss improved from 0.47778 to 0.46283; runtime 0:00:03; BEST YET
Epoch 010: val_loss improved from 0.46283 to 0.45293; runtime 0:00:03; BEST YET
Epoch 011: val_loss improved from 0.45293 to 0.43945; runtime 0:00:03; BEST YET
Epoch 012: val_loss improved from 0.43945 to 0.43909; runtime 0:00:03; BEST YET
Epoch 013: val_loss improved from 0.43909 to 0.43400; runtime 0:00:03; BEST YET
Epoch 014: val_loss improved from 0.43400 to 0.42846; runtime 0:00:03; BEST YET
Epoch 015: val_loss improved from 0.42846 to 0.40922; runtime 0:00:03; BEST YET
Epoch 016: val_loss improved from 0.40922 to 0.40281; runtime 0:00:03; BEST YET
Epoch 017: val_loss did not improve from 0.40281; runtime 0:00:03
Epoch 018: val_loss did not improve from 0.40281; runtime 0:00:03
Epoch 019: val_loss improved from 0.40281 to 0.40158; runtime 0:00:03; BEST YET
Epoch 020: val_loss improved from 0.40158 to 0.40106; runtime 0:00:03; BEST YET
Epoch 021: val_loss improved from 0.40106 to 0.39492; runtime 0:00:03; BEST YET
Epoch 022: val_loss did not improve from 0.39492; runtime 0:00:03
Epoch 023: val_loss did not improve from 0.39492; runtime 0:00:03
Epoch 024: val_loss did not improve from 0.39492; runtime 0:00:03
Fold 5 training runtime: 0:01:24

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.82      0.86      0.84       790
        HPL       0.87      0.85      0.86       564
        MWS       0.85      0.82      0.83       604

avg / total       0.84      0.84      0.84      1958

            ----- Confusion Matrix -----
True Labels  EAP  [677  40  73]
             HPL  [ 71 477  16]
             MWS  [ 80  29 495]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 6 of 10 -----
Epoch 001: val_loss improved from inf to 0.70706; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.70706 to 0.61566; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.61566 to 0.60254; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.60254 to 0.55292; runtime 0:00:03; BEST YET
Epoch 005: val_loss did not improve from 0.55292; runtime 0:00:03
Epoch 006: val_loss improved from 0.55292 to 0.52307; runtime 0:00:03; BEST YET
Epoch 007: val_loss improved from 0.52307 to 0.51595; runtime 0:00:03; BEST YET
Epoch 008: val_loss improved from 0.51595 to 0.49739; runtime 0:00:03; BEST YET
Epoch 009: val_loss did not improve from 0.49739; runtime 0:00:03
Epoch 010: val_loss improved from 0.49739 to 0.48059; runtime 0:00:03; BEST YET
Epoch 011: val_loss improved from 0.48059 to 0.46694; runtime 0:00:03; BEST YET
Epoch 012: val_loss did not improve from 0.46694; runtime 0:00:03
Epoch 013: val_loss improved from 0.46694 to 0.45728; runtime 0:00:03; BEST YET
Epoch 014: val_loss did not improve from 0.45728; runtime 0:00:03
Epoch 015: val_loss did not improve from 0.45728; runtime 0:00:03
Epoch 016: val_loss improved from 0.45728 to 0.44532; runtime 0:00:03; BEST YET
Epoch 017: val_loss did not improve from 0.44532; runtime 0:00:03
Epoch 018: val_loss improved from 0.44532 to 0.44404; runtime 0:00:03; BEST YET
Epoch 019: val_loss did not improve from 0.44404; runtime 0:00:03
Epoch 020: val_loss improved from 0.44404 to 0.44036; runtime 0:00:03; BEST YET
Epoch 021: val_loss did not improve from 0.44036; runtime 0:00:03
Epoch 022: val_loss did not improve from 0.44036; runtime 0:00:03
Epoch 023: val_loss did not improve from 0.44036; runtime 0:00:03
Fold 6 training runtime: 0:01:21

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.82      0.81      0.82       790
        HPL       0.86      0.80      0.83       563
        MWS       0.79      0.85      0.82       604

avg / total       0.82      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [640  48 102]
             HPL  [ 72 452  39]
             MWS  [ 66  23 515]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 7 of 10 -----
Epoch 001: val_loss improved from inf to 0.68855; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.68855 to 0.64136; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.64136 to 0.60132; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.60132 to 0.57956; runtime 0:00:03; BEST YET
Epoch 005: val_loss improved from 0.57956 to 0.55984; runtime 0:00:04; BEST YET
Epoch 006: val_loss improved from 0.55984 to 0.54199; runtime 0:00:03; BEST YET
Epoch 007: val_loss did not improve from 0.54199; runtime 0:00:03
Epoch 008: val_loss improved from 0.54199 to 0.53617; runtime 0:00:03; BEST YET
Epoch 009: val_loss improved from 0.53617 to 0.51940; runtime 0:00:03; BEST YET
Epoch 010: val_loss improved from 0.51940 to 0.48979; runtime 0:00:03; BEST YET
Epoch 011: val_loss did not improve from 0.48979; runtime 0:00:03
Epoch 012: val_loss improved from 0.48979 to 0.48215; runtime 0:00:03; BEST YET
Epoch 013: val_loss improved from 0.48215 to 0.47363; runtime 0:00:03; BEST YET
Epoch 014: val_loss improved from 0.47363 to 0.45970; runtime 0:00:03; BEST YET
Epoch 015: val_loss did not improve from 0.45970; runtime 0:00:03
Epoch 016: val_loss improved from 0.45970 to 0.45576; runtime 0:00:03; BEST YET
Epoch 017: val_loss did not improve from 0.45576; runtime 0:00:04
Epoch 018: val_loss did not improve from 0.45576; runtime 0:00:03
Epoch 019: val_loss did not improve from 0.45576; runtime 0:00:03
Fold 7 training runtime: 0:01:07

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.81      0.83      0.82       790
        HPL       0.88      0.77      0.82       563
        MWS       0.79      0.85      0.82       604

avg / total       0.82      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [659  42  89]
             HPL  [ 84 434  45]
             MWS  [ 72  17 515]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 8 of 10 -----
Epoch 001: val_loss improved from inf to 0.72826; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.72826 to 0.59904; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.59904 to 0.56773; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.56773 to 0.56078; runtime 0:00:03; BEST YET
Epoch 005: val_loss improved from 0.56078 to 0.53669; runtime 0:00:03; BEST YET
Epoch 006: val_loss improved from 0.53669 to 0.52510; runtime 0:00:03; BEST YET
Epoch 007: val_loss improved from 0.52510 to 0.50399; runtime 0:00:03; BEST YET
Epoch 008: val_loss improved from 0.50399 to 0.48733; runtime 0:00:03; BEST YET
Epoch 009: val_loss improved from 0.48733 to 0.47164; runtime 0:00:03; BEST YET
Epoch 010: val_loss improved from 0.47164 to 0.46264; runtime 0:00:03; BEST YET
Epoch 011: val_loss improved from 0.46264 to 0.46170; runtime 0:00:03; BEST YET
Epoch 012: val_loss did not improve from 0.46170; runtime 0:00:03
Epoch 013: val_loss improved from 0.46170 to 0.43053; runtime 0:00:03; BEST YET
Epoch 014: val_loss did not improve from 0.43053; runtime 0:00:03
Epoch 015: val_loss improved from 0.43053 to 0.42464; runtime 0:00:03; BEST YET
Epoch 016: val_loss improved from 0.42464 to 0.41637; runtime 0:00:03; BEST YET
Epoch 017: val_loss did not improve from 0.41637; runtime 0:00:03
Epoch 018: val_loss improved from 0.41637 to 0.41306; runtime 0:00:03; BEST YET
Epoch 019: val_loss did not improve from 0.41306; runtime 0:00:04
Epoch 020: val_loss did not improve from 0.41306; runtime 0:00:03
Epoch 021: val_loss did not improve from 0.41306; runtime 0:00:04
Fold 8 training runtime: 0:01:14

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.81      0.87      0.84       790
        HPL       0.93      0.74      0.82       563
        MWS       0.78      0.85      0.82       604

avg / total       0.83      0.83      0.83      1957

            ----- Confusion Matrix -----
True Labels  EAP  [687  19  84]
             HPL  [ 88 415  60]
             MWS  [ 77  12 515]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 9 of 10 -----
Epoch 001: val_loss improved from inf to 0.69571; runtime 0:00:05; BEST YET
Epoch 002: val_loss improved from 0.69571 to 0.60836; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.60836 to 0.59393; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.59393 to 0.57196; runtime 0:00:03; BEST YET
Epoch 005: val_loss improved from 0.57196 to 0.55090; runtime 0:00:03; BEST YET
Epoch 006: val_loss improved from 0.55090 to 0.52841; runtime 0:00:03; BEST YET
Epoch 007: val_loss improved from 0.52841 to 0.51312; runtime 0:00:03; BEST YET
Epoch 008: val_loss improved from 0.51312 to 0.49860; runtime 0:00:03; BEST YET
Epoch 009: val_loss improved from 0.49860 to 0.47628; runtime 0:00:03; BEST YET
Epoch 010: val_loss did not improve from 0.47628; runtime 0:00:03
Epoch 011: val_loss improved from 0.47628 to 0.46025; runtime 0:00:03; BEST YET
Epoch 012: val_loss improved from 0.46025 to 0.44510; runtime 0:00:03; BEST YET
Epoch 013: val_loss did not improve from 0.44510; runtime 0:00:03
Epoch 014: val_loss did not improve from 0.44510; runtime 0:00:03
Epoch 015: val_loss improved from 0.44510 to 0.42687; runtime 0:00:03; BEST YET
Epoch 016: val_loss did not improve from 0.42687; runtime 0:00:03
Epoch 017: val_loss did not improve from 0.42687; runtime 0:00:03
Epoch 018: val_loss did not improve from 0.42687; runtime 0:00:03
Fold 9 training runtime: 0:01:03

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.82      0.85      0.84       790
        HPL       0.90      0.77      0.83       563
        MWS       0.78      0.86      0.82       604

avg / total       0.83      0.83      0.83      1957

            ----- Confusion Matrix -----
True Labels  EAP  [668  35  87]
             HPL  [ 72 433  58]
             MWS  [ 70  14 520]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 10 of 10 -----
Epoch 001: val_loss improved from inf to 0.68901; runtime 0:00:04; BEST YET
Epoch 002: val_loss improved from 0.68901 to 0.59031; runtime 0:00:03; BEST YET
Epoch 003: val_loss improved from 0.59031 to 0.56814; runtime 0:00:03; BEST YET
Epoch 004: val_loss improved from 0.56814 to 0.56457; runtime 0:00:03; BEST YET
Epoch 005: val_loss improved from 0.56457 to 0.52972; runtime 0:00:03; BEST YET
Epoch 006: val_loss improved from 0.52972 to 0.51314; runtime 0:00:03; BEST YET
Epoch 007: val_loss improved from 0.51314 to 0.49281; runtime 0:00:03; BEST YET
Epoch 008: val_loss did not improve from 0.49281; runtime 0:00:03
Epoch 009: val_loss improved from 0.49281 to 0.46363; runtime 0:00:03; BEST YET
Epoch 010: val_loss improved from 0.46363 to 0.45339; runtime 0:00:03; BEST YET
Epoch 011: val_loss improved from 0.45339 to 0.44498; runtime 0:00:03; BEST YET
Epoch 012: val_loss improved from 0.44498 to 0.43694; runtime 0:00:03; BEST YET
Epoch 013: val_loss improved from 0.43694 to 0.42303; runtime 0:00:03; BEST YET
Epoch 014: val_loss improved from 0.42303 to 0.41788; runtime 0:00:03; BEST YET
Epoch 015: val_loss did not improve from 0.41788; runtime 0:00:03
Epoch 016: val_loss did not improve from 0.41788; runtime 0:00:03
Epoch 017: val_loss did not improve from 0.41788; runtime 0:00:03
Fold 10 training runtime: 0:01:00

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.80      0.89      0.84       790
        HPL       0.92      0.77      0.83       563
        MWS       0.82      0.82      0.82       604

avg / total       0.84      0.83      0.83      1957

            ----- Confusion Matrix -----
True Labels  EAP  [701  29  60]
             HPL  [ 82 432  49]
             MWS  [ 95  11 498]
                    EAP  HPL  MWS
                  Predicted Labels
