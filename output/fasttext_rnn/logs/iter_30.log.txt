_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_layer (InputLayer)     (None, 128)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 128, 300)          8329800   
_________________________________________________________________
spatial_dropout1d_1 (Spatial (None, 128, 300)          0         
_________________________________________________________________
bidirectional_1 (Bidirection (None, 128, 512)          1142784   
_________________________________________________________________
spatial_dropout1d_2 (Spatial (None, 128, 512)          0         
_________________________________________________________________
bidirectional_2 (Bidirection (None, 128, 512)          1576960   
_________________________________________________________________
global_max_pooling1d_1 (Glob (None, 512)               0         
_________________________________________________________________
output_layer (Dense)         (None, 3)                 1539      
=================================================================
Total params: 11,051,083
Trainable params: 2,721,283
Non-trainable params: 8,329,800
_________________________________________________________________


----- Fold 1 of 10 -----
Epoch 001: val_loss improved from inf to 0.72994; runtime 0:00:13; BEST YET
Epoch 002: val_loss did not improve from 0.72994; runtime 0:00:12
Epoch 003: val_loss improved from 0.72994 to 0.56405; runtime 0:00:12; BEST YET
Epoch 004: val_loss improved from 0.56405 to 0.55032; runtime 0:00:12; BEST YET
Epoch 005: val_loss improved from 0.55032 to 0.53020; runtime 0:00:12; BEST YET
Epoch 006: val_loss did not improve from 0.53020; runtime 0:00:12
Epoch 007: val_loss did not improve from 0.53020; runtime 0:00:12
Epoch 008: val_loss did not improve from 0.53020; runtime 0:00:12
Fold 1 training runtime: 0:01:34

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.75      0.85      0.80       790
        HPL       0.94      0.62      0.75       564
        MWS       0.74      0.84      0.79       605

avg / total       0.80      0.78      0.78      1959

            ----- Confusion Matrix -----
True Labels  EAP  [673  13 104]
             HPL  [142 349  73]
             MWS  [ 88   8 509]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 2 of 10 -----
Epoch 001: val_loss improved from inf to 0.65908; runtime 0:00:13; BEST YET
Epoch 002: val_loss improved from 0.65908 to 0.60078; runtime 0:00:12; BEST YET
Epoch 003: val_loss improved from 0.60078 to 0.54937; runtime 0:00:12; BEST YET
Epoch 004: val_loss improved from 0.54937 to 0.52106; runtime 0:00:12; BEST YET
Epoch 005: val_loss improved from 0.52106 to 0.51196; runtime 0:00:12; BEST YET
Epoch 006: val_loss improved from 0.51196 to 0.48953; runtime 0:00:12; BEST YET
Epoch 007: val_loss did not improve from 0.48953; runtime 0:00:12
Epoch 008: val_loss did not improve from 0.48953; runtime 0:00:12
Epoch 009: val_loss improved from 0.48953 to 0.42801; runtime 0:00:12; BEST YET
Epoch 010: val_loss did not improve from 0.42801; runtime 0:00:12
Epoch 011: val_loss did not improve from 0.42801; runtime 0:00:12
Epoch 012: val_loss did not improve from 0.42801; runtime 0:00:12
Fold 2 training runtime: 0:02:21

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.89      0.68      0.77       790
        HPL       0.72      0.92      0.81       564
        MWS       0.79      0.82      0.81       605

avg / total       0.81      0.79      0.79      1959

            ----- Confusion Matrix -----
True Labels  EAP  [540 139 111]
             HPL  [ 22 518  24]
             MWS  [ 46  60 499]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 3 of 10 -----
Epoch 001: val_loss improved from inf to 0.69760; runtime 0:00:13; BEST YET
Epoch 002: val_loss improved from 0.69760 to 0.61897; runtime 0:00:12; BEST YET
Epoch 003: val_loss improved from 0.61897 to 0.61771; runtime 0:00:12; BEST YET
Epoch 004: val_loss improved from 0.61771 to 0.54224; runtime 0:00:12; BEST YET
Epoch 005: val_loss did not improve from 0.54224; runtime 0:00:12
Epoch 006: val_loss did not improve from 0.54224; runtime 0:00:12
Epoch 007: val_loss improved from 0.54224 to 0.51311; runtime 0:00:12; BEST YET
Epoch 008: val_loss improved from 0.51311 to 0.47462; runtime 0:00:12; BEST YET
Epoch 009: val_loss did not improve from 0.47462; runtime 0:00:12
Epoch 010: val_loss improved from 0.47462 to 0.45790; runtime 0:00:12; BEST YET
Epoch 011: val_loss did not improve from 0.45790; runtime 0:00:12
Epoch 012: val_loss did not improve from 0.45790; runtime 0:00:12
Epoch 013: val_loss improved from 0.45790 to 0.45514; runtime 0:00:12; BEST YET
Epoch 014: val_loss did not improve from 0.45514; runtime 0:00:12
Epoch 015: val_loss did not improve from 0.45514; runtime 0:00:12
Epoch 016: val_loss improved from 0.45514 to 0.44255; runtime 0:00:12; BEST YET
Epoch 017: val_loss did not improve from 0.44255; runtime 0:00:12
Epoch 018: val_loss did not improve from 0.44255; runtime 0:00:12
Epoch 019: val_loss did not improve from 0.44255; runtime 0:00:12
Fold 3 training runtime: 0:03:42

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.81      0.84      0.83       790
        HPL       0.94      0.68      0.79       564
        MWS       0.74      0.89      0.81       605

avg / total       0.83      0.81      0.81      1959

            ----- Confusion Matrix -----
True Labels  EAP  [667  14 109]
             HPL  [100 383  81]
             MWS  [ 57   9 539]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 4 of 10 -----
Epoch 001: val_loss improved from inf to 0.71316; runtime 0:00:13; BEST YET
Epoch 002: val_loss improved from 0.71316 to 0.61130; runtime 0:00:12; BEST YET
Epoch 003: val_loss improved from 0.61130 to 0.57768; runtime 0:00:12; BEST YET
Epoch 004: val_loss improved from 0.57768 to 0.54598; runtime 0:00:12; BEST YET
Epoch 005: val_loss improved from 0.54598 to 0.50700; runtime 0:00:12; BEST YET
Epoch 006: val_loss improved from 0.50700 to 0.48890; runtime 0:00:12; BEST YET
Epoch 007: val_loss did not improve from 0.48890; runtime 0:00:12
Epoch 008: val_loss improved from 0.48890 to 0.48499; runtime 0:00:12; BEST YET
Epoch 009: val_loss improved from 0.48499 to 0.46661; runtime 0:00:12; BEST YET
Epoch 010: val_loss improved from 0.46661 to 0.43460; runtime 0:00:12; BEST YET
Epoch 011: val_loss did not improve from 0.43460; runtime 0:00:12
Epoch 012: val_loss improved from 0.43460 to 0.42991; runtime 0:00:12; BEST YET
Epoch 013: val_loss did not improve from 0.42991; runtime 0:00:12
Epoch 014: val_loss improved from 0.42991 to 0.42688; runtime 0:00:12; BEST YET
Epoch 015: val_loss improved from 0.42688 to 0.40148; runtime 0:00:12; BEST YET
Epoch 016: val_loss did not improve from 0.40148; runtime 0:00:12
Epoch 017: val_loss improved from 0.40148 to 0.39473; runtime 0:00:12; BEST YET
Epoch 018: val_loss did not improve from 0.39473; runtime 0:00:12
Epoch 019: val_loss did not improve from 0.39473; runtime 0:00:12
Epoch 020: val_loss did not improve from 0.39473; runtime 0:00:12
Fold 4 training runtime: 0:03:54

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.81      0.87      0.84       790
        HPL       0.86      0.82      0.84       564
        MWS       0.88      0.83      0.85       605

avg / total       0.85      0.84      0.84      1959

            ----- Confusion Matrix -----
True Labels  EAP  [691  54  45]
             HPL  [ 77 463  24]
             MWS  [ 84  21 500]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 5 of 10 -----
Epoch 001: val_loss improved from inf to 0.87986; runtime 0:00:13; BEST YET
Epoch 002: val_loss improved from 0.87986 to 0.81547; runtime 0:00:12; BEST YET
Epoch 003: val_loss improved from 0.81547 to 0.55132; runtime 0:00:12; BEST YET
Epoch 004: val_loss improved from 0.55132 to 0.52632; runtime 0:00:12; BEST YET
Epoch 005: val_loss did not improve from 0.52632; runtime 0:00:12
Epoch 006: val_loss did not improve from 0.52632; runtime 0:00:12
Epoch 007: val_loss improved from 0.52632 to 0.51999; runtime 0:00:12; BEST YET
Epoch 008: val_loss improved from 0.51999 to 0.44485; runtime 0:00:12; BEST YET
Epoch 009: val_loss did not improve from 0.44485; runtime 0:00:12
Epoch 010: val_loss improved from 0.44485 to 0.42258; runtime 0:00:12; BEST YET
Epoch 011: val_loss did not improve from 0.42258; runtime 0:00:12
Epoch 012: val_loss did not improve from 0.42258; runtime 0:00:12
Epoch 013: val_loss did not improve from 0.42258; runtime 0:00:12
Fold 5 training runtime: 0:02:33

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.89      0.71      0.79       790
        HPL       0.83      0.85      0.84       564
        MWS       0.73      0.91      0.81       604

avg / total       0.83      0.81      0.81      1958

            ----- Confusion Matrix -----
True Labels  EAP  [562  72 156]
             HPL  [ 36 479  49]
             MWS  [ 30  24 550]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 6 of 10 -----
Epoch 001: val_loss improved from inf to 0.65913; runtime 0:00:13; BEST YET
Epoch 002: val_loss improved from 0.65913 to 0.61997; runtime 0:00:12; BEST YET
Epoch 003: val_loss improved from 0.61997 to 0.56595; runtime 0:00:12; BEST YET
Epoch 004: val_loss improved from 0.56595 to 0.54926; runtime 0:00:12; BEST YET
Epoch 005: val_loss improved from 0.54926 to 0.51480; runtime 0:00:12; BEST YET
Epoch 006: val_loss did not improve from 0.51480; runtime 0:00:12
Epoch 007: val_loss improved from 0.51480 to 0.51237; runtime 0:00:12; BEST YET
Epoch 008: val_loss improved from 0.51237 to 0.46744; runtime 0:00:12; BEST YET
Epoch 009: val_loss did not improve from 0.46744; runtime 0:00:12
Epoch 010: val_loss did not improve from 0.46744; runtime 0:00:12
Epoch 011: val_loss improved from 0.46744 to 0.46303; runtime 0:00:12; BEST YET
Epoch 012: val_loss improved from 0.46303 to 0.43790; runtime 0:00:12; BEST YET
Epoch 013: val_loss did not improve from 0.43790; runtime 0:00:12
Epoch 014: val_loss did not improve from 0.43790; runtime 0:00:12
Epoch 015: val_loss did not improve from 0.43790; runtime 0:00:12
Fold 6 training runtime: 0:02:56

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.88      0.75      0.81       790
        HPL       0.80      0.89      0.84       563
        MWS       0.79      0.85      0.82       604

avg / total       0.83      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [596  81 113]
             HPL  [ 37 501  25]
             MWS  [ 47  46 511]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 7 of 10 -----
Epoch 001: val_loss improved from inf to 0.70497; runtime 0:00:13; BEST YET
Epoch 002: val_loss improved from 0.70497 to 0.62134; runtime 0:00:12; BEST YET
Epoch 003: val_loss improved from 0.62134 to 0.61167; runtime 0:00:12; BEST YET
Epoch 004: val_loss improved from 0.61167 to 0.56686; runtime 0:00:12; BEST YET
Epoch 005: val_loss improved from 0.56686 to 0.52947; runtime 0:00:12; BEST YET
Epoch 006: val_loss did not improve from 0.52947; runtime 0:00:12
Epoch 007: val_loss improved from 0.52947 to 0.51865; runtime 0:00:12; BEST YET
Epoch 008: val_loss did not improve from 0.51865; runtime 0:00:12
Epoch 009: val_loss improved from 0.51865 to 0.47517; runtime 0:00:12; BEST YET
Epoch 010: val_loss did not improve from 0.47517; runtime 0:00:12
Epoch 011: val_loss improved from 0.47517 to 0.47450; runtime 0:00:12; BEST YET
Epoch 012: val_loss did not improve from 0.47450; runtime 0:00:12
Epoch 013: val_loss did not improve from 0.47450; runtime 0:00:12
Epoch 014: val_loss improved from 0.47450 to 0.44845; runtime 0:00:12; BEST YET
Epoch 015: val_loss did not improve from 0.44845; runtime 0:00:12
Epoch 016: val_loss did not improve from 0.44845; runtime 0:00:12
Epoch 017: val_loss did not improve from 0.44845; runtime 0:00:12
Fold 7 training runtime: 0:03:19

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.88      0.83       790
        HPL       0.92      0.72      0.81       563
        MWS       0.81      0.83      0.82       604

avg / total       0.83      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [697  22  71]
             HPL  [111 408  44]
             MWS  [ 88  14 502]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 8 of 10 -----
Epoch 001: val_loss improved from inf to 0.65899; runtime 0:00:13; BEST YET
Epoch 002: val_loss improved from 0.65899 to 0.58914; runtime 0:00:12; BEST YET
Epoch 003: val_loss did not improve from 0.58914; runtime 0:00:12
Epoch 004: val_loss improved from 0.58914 to 0.55856; runtime 0:00:12; BEST YET
Epoch 005: val_loss improved from 0.55856 to 0.53396; runtime 0:00:12; BEST YET
Epoch 006: val_loss improved from 0.53396 to 0.47812; runtime 0:00:12; BEST YET
Epoch 007: val_loss did not improve from 0.47812; runtime 0:00:12
Epoch 008: val_loss improved from 0.47812 to 0.45431; runtime 0:00:12; BEST YET
Epoch 009: val_loss did not improve from 0.45431; runtime 0:00:12
Epoch 010: val_loss did not improve from 0.45431; runtime 0:00:12
Epoch 011: val_loss improved from 0.45431 to 0.42577; runtime 0:00:12; BEST YET
Epoch 012: val_loss did not improve from 0.42577; runtime 0:00:12
Epoch 013: val_loss did not improve from 0.42577; runtime 0:00:12
Epoch 014: val_loss did not improve from 0.42577; runtime 0:00:12
Fold 8 training runtime: 0:02:44

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.84      0.82      0.83       790
        HPL       0.88      0.82      0.84       563
        MWS       0.79      0.86      0.83       604

avg / total       0.83      0.83      0.83      1957

            ----- Confusion Matrix -----
True Labels  EAP  [648  49  93]
             HPL  [ 61 459  43]
             MWS  [ 67  16 521]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 9 of 10 -----
Epoch 001: val_loss improved from inf to 0.76947; runtime 0:00:13; BEST YET
Epoch 002: val_loss improved from 0.76947 to 0.64672; runtime 0:00:12; BEST YET
Epoch 003: val_loss improved from 0.64672 to 0.59320; runtime 0:00:12; BEST YET
Epoch 004: val_loss did not improve from 0.59320; runtime 0:00:12
Epoch 005: val_loss improved from 0.59320 to 0.51924; runtime 0:00:12; BEST YET
Epoch 006: val_loss improved from 0.51924 to 0.50930; runtime 0:00:12; BEST YET
Epoch 007: val_loss improved from 0.50930 to 0.48950; runtime 0:00:12; BEST YET
Epoch 008: val_loss did not improve from 0.48950; runtime 0:00:12
Epoch 009: val_loss improved from 0.48950 to 0.45787; runtime 0:00:12; BEST YET
Epoch 010: val_loss did not improve from 0.45787; runtime 0:00:12
Epoch 011: val_loss did not improve from 0.45787; runtime 0:00:12
Epoch 012: val_loss did not improve from 0.45787; runtime 0:00:12
Fold 9 training runtime: 0:02:21

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.75      0.89      0.82       790
        HPL       0.88      0.72      0.79       563
        MWS       0.87      0.79      0.83       604

avg / total       0.82      0.81      0.81      1957

            ----- Confusion Matrix -----
True Labels  EAP  [707  40  43]
             HPL  [124 408  31]
             MWS  [109  17 478]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 10 of 10 -----
Epoch 001: val_loss improved from inf to 0.77118; runtime 0:00:13; BEST YET
Epoch 002: val_loss improved from 0.77118 to 0.62374; runtime 0:00:12; BEST YET
Epoch 003: val_loss improved from 0.62374 to 0.56355; runtime 0:00:12; BEST YET
Epoch 004: val_loss improved from 0.56355 to 0.54800; runtime 0:00:12; BEST YET
Epoch 005: val_loss improved from 0.54800 to 0.54461; runtime 0:00:12; BEST YET
Epoch 006: val_loss improved from 0.54461 to 0.47637; runtime 0:00:12; BEST YET
Epoch 007: val_loss did not improve from 0.47637; runtime 0:00:12
Epoch 008: val_loss did not improve from 0.47637; runtime 0:00:12
Epoch 009: val_loss did not improve from 0.47637; runtime 0:00:12
Fold 10 training runtime: 0:01:46

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.85      0.75      0.80       790
        HPL       0.74      0.88      0.81       563
        MWS       0.81      0.80      0.81       604

avg / total       0.81      0.80      0.80      1957

            ----- Confusion Matrix -----
True Labels  EAP  [589 116  85]
             HPL  [ 38 498  27]
             MWS  [ 62  56 486]
                    EAP  HPL  MWS
                  Predicted Labels
