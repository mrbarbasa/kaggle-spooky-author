__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_layer (InputLayer)        (None, 128)          0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 128, 300)     8329800     input_layer[0][0]                
__________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDro (None, 128, 300)     0           embedding_1[0][0]                
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128, 256)     330240      spatial_dropout1d_1[0][0]        
__________________________________________________________________________________________________
global_average_pooling1d_1 (Glo (None, 256)          0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 256)          0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 512)          0           global_average_pooling1d_1[0][0] 
                                                                 global_max_pooling1d_1[0][0]     
__________________________________________________________________________________________________
output_layer (Dense)            (None, 3)            1539        concatenate_1[0][0]              
==================================================================================================
Total params: 8,661,579
Trainable params: 331,779
Non-trainable params: 8,329,800
__________________________________________________________________________________________________


----- Fold 1 of 10 -----
Epoch 001: val_loss improved from inf to 0.72294; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.72294 to 0.64823; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.64823 to 0.61365; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.61365 to 0.59730; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.59730 to 0.58449; runtime 0:00:02; BEST YET
Epoch 006: val_loss improved from 0.58449 to 0.56100; runtime 0:00:02; BEST YET
Epoch 007: val_loss improved from 0.56100 to 0.54234; runtime 0:00:02; BEST YET
Epoch 008: val_loss improved from 0.54234 to 0.53493; runtime 0:00:02; BEST YET
Epoch 009: val_loss improved from 0.53493 to 0.50209; runtime 0:00:02; BEST YET
Epoch 010: val_loss did not improve from 0.50209; runtime 0:00:02
Epoch 011: val_loss did not improve from 0.50209; runtime 0:00:02
Epoch 012: val_loss improved from 0.50209 to 0.47504; runtime 0:00:02; BEST YET
Epoch 013: val_loss did not improve from 0.47504; runtime 0:00:02
Epoch 014: val_loss improved from 0.47504 to 0.47419; runtime 0:00:02; BEST YET
Epoch 015: val_loss improved from 0.47419 to 0.47156; runtime 0:00:02; BEST YET
Epoch 016: val_loss did not improve from 0.47156; runtime 0:00:02
Epoch 017: val_loss improved from 0.47156 to 0.44983; runtime 0:00:02; BEST YET
Epoch 018: val_loss improved from 0.44983 to 0.44086; runtime 0:00:02; BEST YET
Epoch 019: val_loss did not improve from 0.44086; runtime 0:00:02
Epoch 020: val_loss improved from 0.44086 to 0.41482; runtime 0:00:02; BEST YET
Epoch 021: val_loss did not improve from 0.41482; runtime 0:00:02
Epoch 022: val_loss did not improve from 0.41482; runtime 0:00:02
Epoch 023: val_loss did not improve from 0.41482; runtime 0:00:02
Fold 1 training runtime: 0:00:38

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.74      0.94      0.83       790
        HPL       0.94      0.70      0.80       564
        MWS       0.89      0.79      0.84       605

avg / total       0.84      0.82      0.82      1959

            ----- Confusion Matrix -----
True Labels  EAP  [740  16  34]
             HPL  [144 393  27]
             MWS  [118   7 480]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 2 of 10 -----
Epoch 001: val_loss improved from inf to 0.66687; runtime 0:00:02; BEST YET
Epoch 002: val_loss did not improve from 0.66687; runtime 0:00:02
Epoch 003: val_loss did not improve from 0.66687; runtime 0:00:02
Epoch 004: val_loss improved from 0.66687 to 0.58588; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.58588 to 0.55046; runtime 0:00:02; BEST YET
Epoch 006: val_loss improved from 0.55046 to 0.53882; runtime 0:00:02; BEST YET
Epoch 007: val_loss improved from 0.53882 to 0.53301; runtime 0:00:02; BEST YET
Epoch 008: val_loss improved from 0.53301 to 0.50081; runtime 0:00:02; BEST YET
Epoch 009: val_loss did not improve from 0.50081; runtime 0:00:02
Epoch 010: val_loss improved from 0.50081 to 0.49379; runtime 0:00:02; BEST YET
Epoch 011: val_loss improved from 0.49379 to 0.47373; runtime 0:00:02; BEST YET
Epoch 012: val_loss did not improve from 0.47373; runtime 0:00:02
Epoch 013: val_loss improved from 0.47373 to 0.43693; runtime 0:00:02; BEST YET
Epoch 014: val_loss improved from 0.43693 to 0.43652; runtime 0:00:02; BEST YET
Epoch 015: val_loss improved from 0.43652 to 0.41069; runtime 0:00:02; BEST YET
Epoch 016: val_loss improved from 0.41069 to 0.40826; runtime 0:00:02; BEST YET
Epoch 017: val_loss did not improve from 0.40826; runtime 0:00:02
Epoch 018: val_loss did not improve from 0.40826; runtime 0:00:02
Epoch 019: val_loss did not improve from 0.40826; runtime 0:00:02
Fold 2 training runtime: 0:00:32

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.92      0.84       790
        HPL       0.94      0.75      0.83       564
        MWS       0.85      0.81      0.83       605

avg / total       0.85      0.83      0.83      1959

            ----- Confusion Matrix -----
True Labels  EAP  [725  16  49]
             HPL  [104 421  39]
             MWS  [104  12 489]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 3 of 10 -----
Epoch 001: val_loss improved from inf to 0.72885; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.72885 to 0.66080; runtime 0:00:02; BEST YET
Epoch 003: val_loss did not improve from 0.66080; runtime 0:00:02
Epoch 004: val_loss improved from 0.66080 to 0.58821; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.58821 to 0.56944; runtime 0:00:02; BEST YET
Epoch 006: val_loss did not improve from 0.56944; runtime 0:00:02
Epoch 007: val_loss improved from 0.56944 to 0.55631; runtime 0:00:02; BEST YET
Epoch 008: val_loss improved from 0.55631 to 0.52957; runtime 0:00:02; BEST YET
Epoch 009: val_loss did not improve from 0.52957; runtime 0:00:02
Epoch 010: val_loss improved from 0.52957 to 0.51643; runtime 0:00:02; BEST YET
Epoch 011: val_loss did not improve from 0.51643; runtime 0:00:02
Epoch 012: val_loss did not improve from 0.51643; runtime 0:00:02
Epoch 013: val_loss improved from 0.51643 to 0.51237; runtime 0:00:02; BEST YET
Epoch 014: val_loss improved from 0.51237 to 0.48178; runtime 0:00:02; BEST YET
Epoch 015: val_loss improved from 0.48178 to 0.45991; runtime 0:00:02; BEST YET
Epoch 016: val_loss did not improve from 0.45991; runtime 0:00:02
Epoch 017: val_loss improved from 0.45991 to 0.45373; runtime 0:00:02; BEST YET
Epoch 018: val_loss did not improve from 0.45373; runtime 0:00:02
Epoch 019: val_loss improved from 0.45373 to 0.44394; runtime 0:00:02; BEST YET
Epoch 020: val_loss did not improve from 0.44394; runtime 0:00:02
Epoch 021: val_loss did not improve from 0.44394; runtime 0:00:02
Epoch 022: val_loss did not improve from 0.44394; runtime 0:00:02
Fold 3 training runtime: 0:00:36

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.75      0.92      0.83       790
        HPL       0.94      0.67      0.78       564
        MWS       0.82      0.80      0.81       605

avg / total       0.83      0.81      0.81      1959

            ----- Confusion Matrix -----
True Labels  EAP  [725  16  49]
             HPL  [130 380  54]
             MWS  [111   9 485]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 4 of 10 -----
Epoch 001: val_loss improved from inf to 0.68069; runtime 0:00:02; BEST YET
Epoch 002: val_loss did not improve from 0.68069; runtime 0:00:02
Epoch 003: val_loss improved from 0.68069 to 0.59487; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.59487 to 0.58752; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.58752 to 0.55266; runtime 0:00:02; BEST YET
Epoch 006: val_loss improved from 0.55266 to 0.54866; runtime 0:00:02; BEST YET
Epoch 007: val_loss improved from 0.54866 to 0.52026; runtime 0:00:02; BEST YET
Epoch 008: val_loss did not improve from 0.52026; runtime 0:00:02
Epoch 009: val_loss did not improve from 0.52026; runtime 0:00:02
Epoch 010: val_loss improved from 0.52026 to 0.48056; runtime 0:00:02; BEST YET
Epoch 011: val_loss did not improve from 0.48056; runtime 0:00:02
Epoch 012: val_loss improved from 0.48056 to 0.46953; runtime 0:00:02; BEST YET
Epoch 013: val_loss did not improve from 0.46953; runtime 0:00:02
Epoch 014: val_loss improved from 0.46953 to 0.44243; runtime 0:00:02; BEST YET
Epoch 015: val_loss did not improve from 0.44243; runtime 0:00:02
Epoch 016: val_loss did not improve from 0.44243; runtime 0:00:02
Epoch 017: val_loss did not improve from 0.44243; runtime 0:00:02
Fold 4 training runtime: 0:00:28

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.81      0.83      0.82       790
        HPL       0.92      0.68      0.78       564
        MWS       0.74      0.89      0.81       605

avg / total       0.82      0.81      0.81      1959

            ----- Confusion Matrix -----
True Labels  EAP  [653  28 109]
             HPL  [ 99 386  79]
             MWS  [ 58   7 540]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 5 of 10 -----
Epoch 001: val_loss improved from inf to 0.73104; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.73104 to 0.62791; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.62791 to 0.58385; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.58385 to 0.56184; runtime 0:00:02; BEST YET
Epoch 005: val_loss did not improve from 0.56184; runtime 0:00:02
Epoch 006: val_loss improved from 0.56184 to 0.51457; runtime 0:00:02; BEST YET
Epoch 007: val_loss improved from 0.51457 to 0.50114; runtime 0:00:02; BEST YET
Epoch 008: val_loss improved from 0.50114 to 0.49316; runtime 0:00:02; BEST YET
Epoch 009: val_loss improved from 0.49316 to 0.48624; runtime 0:00:02; BEST YET
Epoch 010: val_loss improved from 0.48624 to 0.45850; runtime 0:00:02; BEST YET
Epoch 011: val_loss did not improve from 0.45850; runtime 0:00:02
Epoch 012: val_loss improved from 0.45850 to 0.44906; runtime 0:00:02; BEST YET
Epoch 013: val_loss did not improve from 0.44906; runtime 0:00:02
Epoch 014: val_loss improved from 0.44906 to 0.44113; runtime 0:00:02; BEST YET
Epoch 015: val_loss improved from 0.44113 to 0.42224; runtime 0:00:02; BEST YET
Epoch 016: val_loss improved from 0.42224 to 0.41619; runtime 0:00:02; BEST YET
Epoch 017: val_loss did not improve from 0.41619; runtime 0:00:02
Epoch 018: val_loss did not improve from 0.41619; runtime 0:00:02
Epoch 019: val_loss did not improve from 0.41619; runtime 0:00:02
Fold 5 training runtime: 0:00:32

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.81      0.85      0.83       790
        HPL       0.94      0.71      0.81       564
        MWS       0.76      0.90      0.82       604

avg / total       0.84      0.82      0.82      1958

            ----- Confusion Matrix -----
True Labels  EAP  [668  19 103]
             HPL  [ 94 403  67]
             MWS  [ 58   5 541]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 6 of 10 -----
Epoch 001: val_loss improved from inf to 0.66247; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.66247 to 0.62141; runtime 0:00:02; BEST YET
Epoch 003: val_loss did not improve from 0.62141; runtime 0:00:02
Epoch 004: val_loss improved from 0.62141 to 0.59990; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.59990 to 0.56699; runtime 0:00:02; BEST YET
Epoch 006: val_loss improved from 0.56699 to 0.56029; runtime 0:00:02; BEST YET
Epoch 007: val_loss improved from 0.56029 to 0.54697; runtime 0:00:02; BEST YET
Epoch 008: val_loss improved from 0.54697 to 0.51690; runtime 0:00:02; BEST YET
Epoch 009: val_loss did not improve from 0.51690; runtime 0:00:02
Epoch 010: val_loss improved from 0.51690 to 0.50920; runtime 0:00:02; BEST YET
Epoch 011: val_loss improved from 0.50920 to 0.47257; runtime 0:00:02; BEST YET
Epoch 012: val_loss did not improve from 0.47257; runtime 0:00:02
Epoch 013: val_loss improved from 0.47257 to 0.46160; runtime 0:00:02; BEST YET
Epoch 014: val_loss did not improve from 0.46160; runtime 0:00:02
Epoch 015: val_loss improved from 0.46160 to 0.43986; runtime 0:00:02; BEST YET
Epoch 016: val_loss did not improve from 0.43986; runtime 0:00:02
Epoch 017: val_loss improved from 0.43986 to 0.43236; runtime 0:00:02; BEST YET
Epoch 018: val_loss did not improve from 0.43236; runtime 0:00:02
Epoch 019: val_loss improved from 0.43236 to 0.42404; runtime 0:00:02; BEST YET
Epoch 020: val_loss improved from 0.42404 to 0.41551; runtime 0:00:02; BEST YET
Epoch 021: val_loss improved from 0.41551 to 0.40959; runtime 0:00:02; BEST YET
Epoch 022: val_loss did not improve from 0.40959; runtime 0:00:02
Epoch 023: val_loss improved from 0.40959 to 0.40702; runtime 0:00:02; BEST YET
Epoch 024: val_loss did not improve from 0.40702; runtime 0:00:02
Epoch 025: val_loss did not improve from 0.40702; runtime 0:00:02
Epoch 026: val_loss did not improve from 0.40702; runtime 0:00:02
Fold 6 training runtime: 0:00:43

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.86      0.82      0.84       790
        HPL       0.89      0.82      0.85       563
        MWS       0.79      0.90      0.84       604

avg / total       0.85      0.84      0.84      1957

            ----- Confusion Matrix -----
True Labels  EAP  [646  42 102]
             HPL  [ 59 459  45]
             MWS  [ 50  12 542]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 7 of 10 -----
Epoch 001: val_loss improved from inf to 0.70281; runtime 0:00:02; BEST YET
Epoch 002: val_loss did not improve from 0.70281; runtime 0:00:02
Epoch 003: val_loss improved from 0.70281 to 0.65820; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.65820 to 0.62021; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.62021 to 0.58621; runtime 0:00:02; BEST YET
Epoch 006: val_loss improved from 0.58621 to 0.57026; runtime 0:00:02; BEST YET
Epoch 007: val_loss improved from 0.57026 to 0.57009; runtime 0:00:02; BEST YET
Epoch 008: val_loss improved from 0.57009 to 0.54465; runtime 0:00:02; BEST YET
Epoch 009: val_loss improved from 0.54465 to 0.51354; runtime 0:00:02; BEST YET
Epoch 010: val_loss did not improve from 0.51354; runtime 0:00:02
Epoch 011: val_loss improved from 0.51354 to 0.49165; runtime 0:00:02; BEST YET
Epoch 012: val_loss did not improve from 0.49165; runtime 0:00:02
Epoch 013: val_loss did not improve from 0.49165; runtime 0:00:02
Epoch 014: val_loss improved from 0.49165 to 0.47552; runtime 0:00:02; BEST YET
Epoch 015: val_loss did not improve from 0.47552; runtime 0:00:02
Epoch 016: val_loss improved from 0.47552 to 0.47356; runtime 0:00:02; BEST YET
Epoch 017: val_loss improved from 0.47356 to 0.45343; runtime 0:00:02; BEST YET
Epoch 018: val_loss improved from 0.45343 to 0.45194; runtime 0:00:02; BEST YET
Epoch 019: val_loss did not improve from 0.45194; runtime 0:00:02
Epoch 020: val_loss improved from 0.45194 to 0.43376; runtime 0:00:02; BEST YET
Epoch 021: val_loss improved from 0.43376 to 0.42416; runtime 0:00:02; BEST YET
Epoch 022: val_loss did not improve from 0.42416; runtime 0:00:02
Epoch 023: val_loss did not improve from 0.42416; runtime 0:00:02
Epoch 024: val_loss did not improve from 0.42416; runtime 0:00:02
Fold 7 training runtime: 0:00:40

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.75      0.91      0.82       790
        HPL       0.91      0.74      0.82       563
        MWS       0.86      0.77      0.81       604

avg / total       0.83      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [719  24  47]
             HPL  [119 417  27]
             MWS  [121  17 466]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 8 of 10 -----
Epoch 001: val_loss improved from inf to 0.67373; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.67373 to 0.60176; runtime 0:00:02; BEST YET
Epoch 003: val_loss did not improve from 0.60176; runtime 0:00:02
Epoch 004: val_loss did not improve from 0.60176; runtime 0:00:02
Epoch 005: val_loss improved from 0.60176 to 0.58062; runtime 0:00:02; BEST YET
Epoch 006: val_loss improved from 0.58062 to 0.52955; runtime 0:00:02; BEST YET
Epoch 007: val_loss did not improve from 0.52955; runtime 0:00:02
Epoch 008: val_loss improved from 0.52955 to 0.52016; runtime 0:00:02; BEST YET
Epoch 009: val_loss did not improve from 0.52016; runtime 0:00:02
Epoch 010: val_loss did not improve from 0.52016; runtime 0:00:02
Epoch 011: val_loss improved from 0.52016 to 0.50847; runtime 0:00:02; BEST YET
Epoch 012: val_loss improved from 0.50847 to 0.44995; runtime 0:00:02; BEST YET
Epoch 013: val_loss did not improve from 0.44995; runtime 0:00:02
Epoch 014: val_loss did not improve from 0.44995; runtime 0:00:02
Epoch 015: val_loss did not improve from 0.44995; runtime 0:00:02
Fold 8 training runtime: 0:00:25

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.77      0.89      0.83       790
        HPL       0.93      0.71      0.81       563
        MWS       0.81      0.83      0.82       604

avg / total       0.83      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [703  17  70]
             HPL  [114 400  49]
             MWS  [ 91  12 501]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 9 of 10 -----
Epoch 001: val_loss improved from inf to 0.69031; runtime 0:00:02; BEST YET
Epoch 002: val_loss did not improve from 0.69031; runtime 0:00:02
Epoch 003: val_loss improved from 0.69031 to 0.63914; runtime 0:00:02; BEST YET
Epoch 004: val_loss improved from 0.63914 to 0.63541; runtime 0:00:02; BEST YET
Epoch 005: val_loss improved from 0.63541 to 0.58541; runtime 0:00:02; BEST YET
Epoch 006: val_loss improved from 0.58541 to 0.54958; runtime 0:00:02; BEST YET
Epoch 007: val_loss improved from 0.54958 to 0.53786; runtime 0:00:02; BEST YET
Epoch 008: val_loss improved from 0.53786 to 0.52296; runtime 0:00:02; BEST YET
Epoch 009: val_loss improved from 0.52296 to 0.50794; runtime 0:00:02; BEST YET
Epoch 010: val_loss improved from 0.50794 to 0.49323; runtime 0:00:02; BEST YET
Epoch 011: val_loss did not improve from 0.49323; runtime 0:00:02
Epoch 012: val_loss did not improve from 0.49323; runtime 0:00:02
Epoch 013: val_loss did not improve from 0.49323; runtime 0:00:02
Fold 9 training runtime: 0:00:22

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.71      0.94      0.81       790
        HPL       0.94      0.64      0.76       563
        MWS       0.89      0.76      0.82       604

avg / total       0.83      0.80      0.80      1957

            ----- Confusion Matrix -----
True Labels  EAP  [741  12  37]
             HPL  [178 363  22]
             MWS  [130  13 461]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 10 of 10 -----
Epoch 001: val_loss improved from inf to 0.68990; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.68990 to 0.60327; runtime 0:00:02; BEST YET
Epoch 003: val_loss improved from 0.60327 to 0.60136; runtime 0:00:02; BEST YET
Epoch 004: val_loss did not improve from 0.60136; runtime 0:00:02
Epoch 005: val_loss improved from 0.60136 to 0.56884; runtime 0:00:02; BEST YET
Epoch 006: val_loss did not improve from 0.56884; runtime 0:00:02
Epoch 007: val_loss improved from 0.56884 to 0.53047; runtime 0:00:02; BEST YET
Epoch 008: val_loss improved from 0.53047 to 0.50180; runtime 0:00:02; BEST YET
Epoch 009: val_loss improved from 0.50180 to 0.49375; runtime 0:00:02; BEST YET
Epoch 010: val_loss improved from 0.49375 to 0.48057; runtime 0:00:02; BEST YET
Epoch 011: val_loss improved from 0.48057 to 0.46739; runtime 0:00:02; BEST YET
Epoch 012: val_loss improved from 0.46739 to 0.45108; runtime 0:00:02; BEST YET
Epoch 013: val_loss did not improve from 0.45108; runtime 0:00:02
Epoch 014: val_loss did not improve from 0.45108; runtime 0:00:02
Epoch 015: val_loss improved from 0.45108 to 0.43355; runtime 0:00:02; BEST YET
Epoch 016: val_loss did not improve from 0.43355; runtime 0:00:02
Epoch 017: val_loss improved from 0.43355 to 0.41764; runtime 0:00:02; BEST YET
Epoch 018: val_loss did not improve from 0.41764; runtime 0:00:02
Epoch 019: val_loss improved from 0.41764 to 0.41231; runtime 0:00:02; BEST YET
Epoch 020: val_loss did not improve from 0.41231; runtime 0:00:02
Epoch 021: val_loss did not improve from 0.41231; runtime 0:00:02
Epoch 022: val_loss improved from 0.41231 to 0.40971; runtime 0:00:02; BEST YET
Epoch 023: val_loss improved from 0.40971 to 0.38861; runtime 0:00:02; BEST YET
Epoch 024: val_loss did not improve from 0.38861; runtime 0:00:02
Epoch 025: val_loss did not improve from 0.38861; runtime 0:00:02
Epoch 026: val_loss did not improve from 0.38861; runtime 0:00:02
Fold 10 training runtime: 0:00:43

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.77      0.92      0.84       790
        HPL       0.89      0.80      0.84       563
        MWS       0.90      0.74      0.81       604

avg / total       0.84      0.83      0.83      1957

            ----- Confusion Matrix -----
True Labels  EAP  [730  30  30]
             HPL  [ 91 451  21]
             MWS  [129  26 449]
                    EAP  HPL  MWS
                  Predicted Labels
