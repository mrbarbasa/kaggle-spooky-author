__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_layer (InputLayer)        (None, 128)          0                                            
__________________________________________________________________________________________________
embedding_1 (Embedding)         (None, 128, 300)     8302800     input_layer[0][0]                
__________________________________________________________________________________________________
spatial_dropout1d_1 (SpatialDro (None, 128, 300)     0           embedding_1[0][0]                
__________________________________________________________________________________________________
bidirectional_1 (Bidirectional) (None, 128, 64)      64128       spatial_dropout1d_1[0][0]        
__________________________________________________________________________________________________
global_average_pooling1d_1 (Glo (None, 64)           0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
global_max_pooling1d_1 (GlobalM (None, 64)           0           bidirectional_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 128)          0           global_average_pooling1d_1[0][0] 
                                                                 global_max_pooling1d_1[0][0]     
__________________________________________________________________________________________________
output_layer (Dense)            (None, 3)            387         concatenate_1[0][0]              
==================================================================================================
Total params: 8,367,315
Trainable params: 64,515
Non-trainable params: 8,302,800
__________________________________________________________________________________________________


----- Fold 1 of 10 -----
Epoch 001: val_loss improved from inf to 0.91303; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.91303 to 0.76581; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.76581 to 0.66663; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.66663 to 0.62642; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.62642 to 0.60021; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.60021 to 0.58255; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.58255 to 0.56995; runtime 0:00:01; BEST YET
Epoch 008: val_loss improved from 0.56995 to 0.56176; runtime 0:00:01; BEST YET
Epoch 009: val_loss improved from 0.56176 to 0.53691; runtime 0:00:01; BEST YET
Epoch 010: val_loss improved from 0.53691 to 0.52027; runtime 0:00:01; BEST YET
Epoch 011: val_loss did not improve from 0.52027; runtime 0:00:01
Epoch 012: val_loss improved from 0.52027 to 0.49981; runtime 0:00:01; BEST YET
Epoch 013: val_loss did not improve from 0.49981; runtime 0:00:01
Epoch 014: val_loss did not improve from 0.49981; runtime 0:00:01
Epoch 015: val_loss improved from 0.49981 to 0.47624; runtime 0:00:01; BEST YET
Epoch 016: val_loss improved from 0.47624 to 0.47474; runtime 0:00:01; BEST YET
Epoch 017: val_loss did not improve from 0.47474; runtime 0:00:01
Epoch 018: val_loss did not improve from 0.47474; runtime 0:00:01
Epoch 019: val_loss did not improve from 0.47474; runtime 0:00:01
Fold 1 training runtime: 0:00:14

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.85      0.81       790
        HPL       0.92      0.67      0.77       564
        MWS       0.76      0.86      0.81       605

avg / total       0.81      0.80      0.80      1959

            ----- Confusion Matrix -----
True Labels  EAP  [669  25  96]
             HPL  [117 378  69]
             MWS  [ 75   9 521]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 2 of 10 -----
Epoch 001: val_loss improved from inf to 0.94522; runtime 0:00:01; BEST YET
Epoch 002: val_loss improved from 0.94522 to 0.79778; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.79778 to 0.67241; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.67241 to 0.62172; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.62172 to 0.59921; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.59921 to 0.57402; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.57402 to 0.53874; runtime 0:00:01; BEST YET
Epoch 008: val_loss did not improve from 0.53874; runtime 0:00:01
Epoch 009: val_loss improved from 0.53874 to 0.51362; runtime 0:00:01; BEST YET
Epoch 010: val_loss did not improve from 0.51362; runtime 0:00:01
Epoch 011: val_loss did not improve from 0.51362; runtime 0:00:01
Epoch 012: val_loss improved from 0.51362 to 0.48968; runtime 0:00:01; BEST YET
Epoch 013: val_loss improved from 0.48968 to 0.47904; runtime 0:00:01; BEST YET
Epoch 014: val_loss did not improve from 0.47904; runtime 0:00:01
Epoch 015: val_loss did not improve from 0.47904; runtime 0:00:01
Epoch 016: val_loss improved from 0.47904 to 0.47465; runtime 0:00:01; BEST YET
Epoch 017: val_loss improved from 0.47465 to 0.47052; runtime 0:00:01; BEST YET
Epoch 018: val_loss improved from 0.47052 to 0.44987; runtime 0:00:01; BEST YET
Epoch 019: val_loss did not improve from 0.44987; runtime 0:00:01
Epoch 020: val_loss improved from 0.44987 to 0.43280; runtime 0:00:01; BEST YET
Epoch 021: val_loss did not improve from 0.43280; runtime 0:00:01
Epoch 022: val_loss did not improve from 0.43280; runtime 0:00:01
Epoch 023: val_loss did not improve from 0.43280; runtime 0:00:01
Fold 2 training runtime: 0:00:17

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.72      0.91      0.81       790
        HPL       0.94      0.68      0.79       564
        MWS       0.85      0.78      0.81       605

avg / total       0.82      0.80      0.80      1959

            ----- Confusion Matrix -----
True Labels  EAP  [720  17  53]
             HPL  [150 381  33]
             MWS  [128   8 469]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 3 of 10 -----
Epoch 001: val_loss improved from inf to 0.95157; runtime 0:00:01; BEST YET
Epoch 002: val_loss improved from 0.95157 to 0.81973; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.81973 to 0.72535; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.72535 to 0.67800; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.67800 to 0.63421; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.63421 to 0.63078; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.63078 to 0.60692; runtime 0:00:01; BEST YET
Epoch 008: val_loss did not improve from 0.60692; runtime 0:00:01
Epoch 009: val_loss improved from 0.60692 to 0.57342; runtime 0:00:01; BEST YET
Epoch 010: val_loss improved from 0.57342 to 0.55559; runtime 0:00:01; BEST YET
Epoch 011: val_loss improved from 0.55559 to 0.55020; runtime 0:00:01; BEST YET
Epoch 012: val_loss improved from 0.55020 to 0.54253; runtime 0:00:01; BEST YET
Epoch 013: val_loss did not improve from 0.54253; runtime 0:00:01
Epoch 014: val_loss improved from 0.54253 to 0.52534; runtime 0:00:01; BEST YET
Epoch 015: val_loss did not improve from 0.52534; runtime 0:00:01
Epoch 016: val_loss improved from 0.52534 to 0.51212; runtime 0:00:01; BEST YET
Epoch 017: val_loss did not improve from 0.51212; runtime 0:00:01
Epoch 018: val_loss improved from 0.51212 to 0.50134; runtime 0:00:01; BEST YET
Epoch 019: val_loss did not improve from 0.50134; runtime 0:00:01
Epoch 020: val_loss did not improve from 0.50134; runtime 0:00:01
Epoch 021: val_loss improved from 0.50134 to 0.49260; runtime 0:00:01; BEST YET
Epoch 022: val_loss did not improve from 0.49260; runtime 0:00:01
Epoch 023: val_loss did not improve from 0.49260; runtime 0:00:01
Epoch 024: val_loss improved from 0.49260 to 0.49118; runtime 0:00:01; BEST YET
Epoch 025: val_loss did not improve from 0.49118; runtime 0:00:01
Epoch 026: val_loss did not improve from 0.49118; runtime 0:00:01
Epoch 027: val_loss did not improve from 0.49118; runtime 0:00:01
Fold 3 training runtime: 0:00:20

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.76      0.86      0.81       790
        HPL       0.89      0.69      0.78       564
        MWS       0.78      0.82      0.80       605

avg / total       0.80      0.80      0.80      1959

            ----- Confusion Matrix -----
True Labels  EAP  [677  34  79]
             HPL  [116 389  59]
             MWS  [ 95  15 495]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 4 of 10 -----
Epoch 001: val_loss improved from inf to 0.94259; runtime 0:00:02; BEST YET
Epoch 002: val_loss improved from 0.94259 to 0.78483; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.78483 to 0.68734; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.68734 to 0.64421; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.64421 to 0.60737; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.60737 to 0.58780; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.58780 to 0.57339; runtime 0:00:01; BEST YET
Epoch 008: val_loss improved from 0.57339 to 0.54780; runtime 0:00:01; BEST YET
Epoch 009: val_loss did not improve from 0.54780; runtime 0:00:01
Epoch 010: val_loss improved from 0.54780 to 0.54068; runtime 0:00:01; BEST YET
Epoch 011: val_loss improved from 0.54068 to 0.52443; runtime 0:00:01; BEST YET
Epoch 012: val_loss improved from 0.52443 to 0.49228; runtime 0:00:01; BEST YET
Epoch 013: val_loss did not improve from 0.49228; runtime 0:00:01
Epoch 014: val_loss did not improve from 0.49228; runtime 0:00:01
Epoch 015: val_loss improved from 0.49228 to 0.47946; runtime 0:00:01; BEST YET
Epoch 016: val_loss improved from 0.47946 to 0.46435; runtime 0:00:01; BEST YET
Epoch 017: val_loss did not improve from 0.46435; runtime 0:00:01
Epoch 018: val_loss improved from 0.46435 to 0.45245; runtime 0:00:01; BEST YET
Epoch 019: val_loss did not improve from 0.45245; runtime 0:00:01
Epoch 020: val_loss improved from 0.45245 to 0.44449; runtime 0:00:01; BEST YET
Epoch 021: val_loss improved from 0.44449 to 0.43851; runtime 0:00:01; BEST YET
Epoch 022: val_loss improved from 0.43851 to 0.42677; runtime 0:00:01; BEST YET
Epoch 023: val_loss did not improve from 0.42677; runtime 0:00:01
Epoch 024: val_loss improved from 0.42677 to 0.42150; runtime 0:00:01; BEST YET
Epoch 025: val_loss did not improve from 0.42150; runtime 0:00:01
Epoch 026: val_loss improved from 0.42150 to 0.40396; runtime 0:00:01; BEST YET
Epoch 027: val_loss did not improve from 0.40396; runtime 0:00:01
Epoch 028: val_loss did not improve from 0.40396; runtime 0:00:01
Epoch 029: val_loss improved from 0.40396 to 0.40127; runtime 0:00:01; BEST YET
Epoch 030: val_loss did not improve from 0.40127; runtime 0:00:01
Epoch 031: val_loss did not improve from 0.40127; runtime 0:00:01
Epoch 032: val_loss did not improve from 0.40127; runtime 0:00:01
Fold 4 training runtime: 0:00:23

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.80      0.86      0.83       790
        HPL       0.95      0.68      0.79       564
        MWS       0.76      0.90      0.83       605

avg / total       0.83      0.82      0.82      1959

            ----- Confusion Matrix -----
True Labels  EAP  [676  17  97]
             HPL  [108 383  73]
             MWS  [ 56   2 547]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 5 of 10 -----
Epoch 001: val_loss improved from inf to 0.92513; runtime 0:00:01; BEST YET
Epoch 002: val_loss improved from 0.92513 to 0.78406; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.78406 to 0.67910; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.67910 to 0.63804; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.63804 to 0.59782; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.59782 to 0.58737; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.58737 to 0.56950; runtime 0:00:01; BEST YET
Epoch 008: val_loss improved from 0.56950 to 0.53966; runtime 0:00:01; BEST YET
Epoch 009: val_loss improved from 0.53966 to 0.53287; runtime 0:00:01; BEST YET
Epoch 010: val_loss improved from 0.53287 to 0.51049; runtime 0:00:01; BEST YET
Epoch 011: val_loss did not improve from 0.51049; runtime 0:00:01
Epoch 012: val_loss improved from 0.51049 to 0.48711; runtime 0:00:01; BEST YET
Epoch 013: val_loss improved from 0.48711 to 0.47338; runtime 0:00:01; BEST YET
Epoch 014: val_loss improved from 0.47338 to 0.46901; runtime 0:00:01; BEST YET
Epoch 015: val_loss improved from 0.46901 to 0.46381; runtime 0:00:01; BEST YET
Epoch 016: val_loss improved from 0.46381 to 0.45442; runtime 0:00:01; BEST YET
Epoch 017: val_loss improved from 0.45442 to 0.45271; runtime 0:00:01; BEST YET
Epoch 018: val_loss improved from 0.45271 to 0.44769; runtime 0:00:01; BEST YET
Epoch 019: val_loss improved from 0.44769 to 0.43483; runtime 0:00:01; BEST YET
Epoch 020: val_loss improved from 0.43483 to 0.43344; runtime 0:00:01; BEST YET
Epoch 021: val_loss did not improve from 0.43344; runtime 0:00:01
Epoch 022: val_loss improved from 0.43344 to 0.42849; runtime 0:00:01; BEST YET
Epoch 023: val_loss improved from 0.42849 to 0.40709; runtime 0:00:01; BEST YET
Epoch 024: val_loss did not improve from 0.40709; runtime 0:00:01
Epoch 025: val_loss did not improve from 0.40709; runtime 0:00:01
Epoch 026: val_loss did not improve from 0.40709; runtime 0:00:01
Fold 5 training runtime: 0:00:19

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.77      0.89      0.83       790
        HPL       0.95      0.69      0.80       564
        MWS       0.81      0.85      0.83       604

avg / total       0.83      0.82      0.82      1958

            ----- Confusion Matrix -----
True Labels  EAP  [706  15  69]
             HPL  [123 390  51]
             MWS  [ 84   7 513]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 6 of 10 -----
Epoch 001: val_loss improved from inf to 0.95669; runtime 0:00:01; BEST YET
Epoch 002: val_loss improved from 0.95669 to 0.80736; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.80736 to 0.69605; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.69605 to 0.63833; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.63833 to 0.60869; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.60869 to 0.58601; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.58601 to 0.56880; runtime 0:00:01; BEST YET
Epoch 008: val_loss improved from 0.56880 to 0.55446; runtime 0:00:01; BEST YET
Epoch 009: val_loss improved from 0.55446 to 0.55431; runtime 0:00:01; BEST YET
Epoch 010: val_loss improved from 0.55431 to 0.55405; runtime 0:00:01; BEST YET
Epoch 011: val_loss improved from 0.55405 to 0.52146; runtime 0:00:01; BEST YET
Epoch 012: val_loss improved from 0.52146 to 0.51083; runtime 0:00:01; BEST YET
Epoch 013: val_loss improved from 0.51083 to 0.50740; runtime 0:00:01; BEST YET
Epoch 014: val_loss improved from 0.50740 to 0.49965; runtime 0:00:01; BEST YET
Epoch 015: val_loss improved from 0.49965 to 0.49501; runtime 0:00:01; BEST YET
Epoch 016: val_loss improved from 0.49501 to 0.48768; runtime 0:00:01; BEST YET
Epoch 017: val_loss improved from 0.48768 to 0.48209; runtime 0:00:01; BEST YET
Epoch 018: val_loss did not improve from 0.48209; runtime 0:00:01
Epoch 019: val_loss improved from 0.48209 to 0.48119; runtime 0:00:01; BEST YET
Epoch 020: val_loss did not improve from 0.48119; runtime 0:00:01
Epoch 021: val_loss did not improve from 0.48119; runtime 0:00:01
Epoch 022: val_loss improved from 0.48119 to 0.47184; runtime 0:00:01; BEST YET
Epoch 023: val_loss improved from 0.47184 to 0.47012; runtime 0:00:01; BEST YET
Epoch 024: val_loss improved from 0.47012 to 0.46699; runtime 0:00:01; BEST YET
Epoch 025: val_loss improved from 0.46699 to 0.46656; runtime 0:00:01; BEST YET
Epoch 026: val_loss did not improve from 0.46656; runtime 0:00:01
Epoch 027: val_loss improved from 0.46656 to 0.45892; runtime 0:00:01; BEST YET
Epoch 028: val_loss improved from 0.45892 to 0.45682; runtime 0:00:01; BEST YET
Epoch 029: val_loss did not improve from 0.45682; runtime 0:00:01
Epoch 030: val_loss did not improve from 0.45682; runtime 0:00:01
Epoch 031: val_loss did not improve from 0.45682; runtime 0:00:01
Fold 6 training runtime: 0:00:23

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.79      0.85      0.82       790
        HPL       0.86      0.82      0.84       563
        MWS       0.83      0.78      0.80       604

avg / total       0.82      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [672  49  69]
             HPL  [ 74 459  30]
             MWS  [105  27 472]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 7 of 10 -----
Epoch 001: val_loss improved from inf to 0.92861; runtime 0:00:01; BEST YET
Epoch 002: val_loss improved from 0.92861 to 0.78258; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.78258 to 0.70865; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.70865 to 0.66541; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.66541 to 0.63567; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.63567 to 0.61751; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.61751 to 0.60536; runtime 0:00:01; BEST YET
Epoch 008: val_loss improved from 0.60536 to 0.57814; runtime 0:00:01; BEST YET
Epoch 009: val_loss did not improve from 0.57814; runtime 0:00:01
Epoch 010: val_loss improved from 0.57814 to 0.56338; runtime 0:00:01; BEST YET
Epoch 011: val_loss improved from 0.56338 to 0.56013; runtime 0:00:01; BEST YET
Epoch 012: val_loss improved from 0.56013 to 0.55519; runtime 0:00:01; BEST YET
Epoch 013: val_loss improved from 0.55519 to 0.52663; runtime 0:00:01; BEST YET
Epoch 014: val_loss improved from 0.52663 to 0.52387; runtime 0:00:01; BEST YET
Epoch 015: val_loss improved from 0.52387 to 0.50221; runtime 0:00:01; BEST YET
Epoch 016: val_loss did not improve from 0.50221; runtime 0:00:01
Epoch 017: val_loss did not improve from 0.50221; runtime 0:00:01
Epoch 018: val_loss did not improve from 0.50221; runtime 0:00:01
Fold 7 training runtime: 0:00:14

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.73      0.90      0.81       790
        HPL       0.92      0.68      0.78       563
        MWS       0.82      0.76      0.79       604

avg / total       0.81      0.80      0.79      1957

            ----- Confusion Matrix -----
True Labels  EAP  [712  22  56]
             HPL  [135 383  45]
             MWS  [129  13 462]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 8 of 10 -----
Epoch 001: val_loss improved from inf to 0.91549; runtime 0:00:01; BEST YET
Epoch 002: val_loss improved from 0.91549 to 0.76899; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.76899 to 0.67421; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.67421 to 0.62621; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.62621 to 0.59736; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.59736 to 0.57302; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.57302 to 0.55605; runtime 0:00:01; BEST YET
Epoch 008: val_loss improved from 0.55605 to 0.53811; runtime 0:00:01; BEST YET
Epoch 009: val_loss did not improve from 0.53811; runtime 0:00:01
Epoch 010: val_loss improved from 0.53811 to 0.52792; runtime 0:00:01; BEST YET
Epoch 011: val_loss improved from 0.52792 to 0.50293; runtime 0:00:01; BEST YET
Epoch 012: val_loss did not improve from 0.50293; runtime 0:00:01
Epoch 013: val_loss improved from 0.50293 to 0.49563; runtime 0:00:01; BEST YET
Epoch 014: val_loss improved from 0.49563 to 0.49148; runtime 0:00:01; BEST YET
Epoch 015: val_loss improved from 0.49148 to 0.47950; runtime 0:00:01; BEST YET
Epoch 016: val_loss did not improve from 0.47950; runtime 0:00:01
Epoch 017: val_loss improved from 0.47950 to 0.46539; runtime 0:00:01; BEST YET
Epoch 018: val_loss improved from 0.46539 to 0.45335; runtime 0:00:01; BEST YET
Epoch 019: val_loss did not improve from 0.45335; runtime 0:00:01
Epoch 020: val_loss improved from 0.45335 to 0.44850; runtime 0:00:01; BEST YET
Epoch 021: val_loss improved from 0.44850 to 0.44172; runtime 0:00:01; BEST YET
Epoch 022: val_loss did not improve from 0.44172; runtime 0:00:01
Epoch 023: val_loss did not improve from 0.44172; runtime 0:00:01
Epoch 024: val_loss improved from 0.44172 to 0.43576; runtime 0:00:01; BEST YET
Epoch 025: val_loss improved from 0.43576 to 0.43077; runtime 0:00:01; BEST YET
Epoch 026: val_loss did not improve from 0.43077; runtime 0:00:01
Epoch 027: val_loss did not improve from 0.43077; runtime 0:00:01
Epoch 028: val_loss improved from 0.43077 to 0.42056; runtime 0:00:01; BEST YET
Epoch 029: val_loss did not improve from 0.42056; runtime 0:00:01
Epoch 030: val_loss did not improve from 0.42056; runtime 0:00:01
Epoch 031: val_loss improved from 0.42056 to 0.41085; runtime 0:00:01; BEST YET
Epoch 032: val_loss did not improve from 0.41085; runtime 0:00:01
Epoch 033: val_loss did not improve from 0.41085; runtime 0:00:01
Epoch 034: val_loss did not improve from 0.41085; runtime 0:00:01
Fold 8 training runtime: 0:00:25

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.78      0.91      0.84       790
        HPL       0.90      0.79      0.84       563
        MWS       0.87      0.78      0.82       604

avg / total       0.84      0.83      0.83      1957

            ----- Confusion Matrix -----
True Labels  EAP  [716  30  44]
             HPL  [ 92 443  28]
             MWS  [112  20 472]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 9 of 10 -----
Epoch 001: val_loss improved from inf to 0.93464; runtime 0:00:01; BEST YET
Epoch 002: val_loss improved from 0.93464 to 0.76813; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.76813 to 0.67506; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.67506 to 0.65063; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.65063 to 0.61131; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.61131 to 0.60645; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.60645 to 0.57753; runtime 0:00:01; BEST YET
Epoch 008: val_loss improved from 0.57753 to 0.56078; runtime 0:00:01; BEST YET
Epoch 009: val_loss improved from 0.56078 to 0.55402; runtime 0:00:01; BEST YET
Epoch 010: val_loss improved from 0.55402 to 0.54935; runtime 0:00:01; BEST YET
Epoch 011: val_loss did not improve from 0.54935; runtime 0:00:01
Epoch 012: val_loss improved from 0.54935 to 0.51501; runtime 0:00:01; BEST YET
Epoch 013: val_loss improved from 0.51501 to 0.51011; runtime 0:00:01; BEST YET
Epoch 014: val_loss improved from 0.51011 to 0.50327; runtime 0:00:01; BEST YET
Epoch 015: val_loss improved from 0.50327 to 0.50122; runtime 0:00:01; BEST YET
Epoch 016: val_loss improved from 0.50122 to 0.49014; runtime 0:00:01; BEST YET
Epoch 017: val_loss improved from 0.49014 to 0.48876; runtime 0:00:01; BEST YET
Epoch 018: val_loss did not improve from 0.48876; runtime 0:00:01
Epoch 019: val_loss improved from 0.48876 to 0.48709; runtime 0:00:01; BEST YET
Epoch 020: val_loss did not improve from 0.48709; runtime 0:00:01
Epoch 021: val_loss did not improve from 0.48709; runtime 0:00:01
Epoch 022: val_loss improved from 0.48709 to 0.47646; runtime 0:00:01; BEST YET
Epoch 023: val_loss did not improve from 0.47646; runtime 0:00:01
Epoch 024: val_loss did not improve from 0.47646; runtime 0:00:01
Epoch 025: val_loss improved from 0.47646 to 0.46072; runtime 0:00:01; BEST YET
Epoch 026: val_loss did not improve from 0.46072; runtime 0:00:01
Epoch 027: val_loss did not improve from 0.46072; runtime 0:00:01
Epoch 028: val_loss did not improve from 0.46072; runtime 0:00:01
Fold 9 training runtime: 0:00:20

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.76      0.89      0.82       790
        HPL       0.93      0.70      0.80       563
        MWS       0.82      0.83      0.82       604

avg / total       0.83      0.82      0.82      1957

            ----- Confusion Matrix -----
True Labels  EAP  [703  20  67]
             HPL  [124 395  44]
             MWS  [ 92  12 500]
                    EAP  HPL  MWS
                  Predicted Labels


----- Fold 10 of 10 -----
Epoch 001: val_loss improved from inf to 0.92255; runtime 0:00:01; BEST YET
Epoch 002: val_loss improved from 0.92255 to 0.75777; runtime 0:00:01; BEST YET
Epoch 003: val_loss improved from 0.75777 to 0.66256; runtime 0:00:01; BEST YET
Epoch 004: val_loss improved from 0.66256 to 0.61513; runtime 0:00:01; BEST YET
Epoch 005: val_loss improved from 0.61513 to 0.59252; runtime 0:00:01; BEST YET
Epoch 006: val_loss improved from 0.59252 to 0.57285; runtime 0:00:01; BEST YET
Epoch 007: val_loss improved from 0.57285 to 0.54593; runtime 0:00:01; BEST YET
Epoch 008: val_loss improved from 0.54593 to 0.53982; runtime 0:00:01; BEST YET
Epoch 009: val_loss improved from 0.53982 to 0.51639; runtime 0:00:01; BEST YET
Epoch 010: val_loss did not improve from 0.51639; runtime 0:00:01
Epoch 011: val_loss improved from 0.51639 to 0.49802; runtime 0:00:01; BEST YET
Epoch 012: val_loss improved from 0.49802 to 0.48842; runtime 0:00:01; BEST YET
Epoch 013: val_loss did not improve from 0.48842; runtime 0:00:01
Epoch 014: val_loss did not improve from 0.48842; runtime 0:00:01
Epoch 015: val_loss improved from 0.48842 to 0.47766; runtime 0:00:01; BEST YET
Epoch 016: val_loss improved from 0.47766 to 0.46710; runtime 0:00:01; BEST YET
Epoch 017: val_loss did not improve from 0.46710; runtime 0:00:01
Epoch 018: val_loss did not improve from 0.46710; runtime 0:00:01
Epoch 019: val_loss improved from 0.46710 to 0.46197; runtime 0:00:01; BEST YET
Epoch 020: val_loss improved from 0.46197 to 0.45920; runtime 0:00:01; BEST YET
Epoch 021: val_loss improved from 0.45920 to 0.45098; runtime 0:00:01; BEST YET
Epoch 022: val_loss improved from 0.45098 to 0.44441; runtime 0:00:01; BEST YET
Epoch 023: val_loss improved from 0.44441 to 0.43918; runtime 0:00:01; BEST YET
Epoch 024: val_loss did not improve from 0.43918; runtime 0:00:01
Epoch 025: val_loss did not improve from 0.43918; runtime 0:00:01
Epoch 026: val_loss did not improve from 0.43918; runtime 0:00:01
Fold 10 training runtime: 0:00:19

            ----- Classification Report -----
             precision    recall  f1-score   support

        EAP       0.77      0.88      0.82       790
        HPL       0.93      0.72      0.81       563
        MWS       0.80      0.82      0.81       604

avg / total       0.82      0.81      0.81      1957

            ----- Confusion Matrix -----
True Labels  EAP  [695  18  77]
             HPL  [111 403  49]
             MWS  [ 96  13 495]
                    EAP  HPL  MWS
                  Predicted Labels
