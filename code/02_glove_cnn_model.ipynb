{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spooky Author Identification: GloVe CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from packages import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'glove_cnn'\n",
    "\n",
    "INPUT_DIR = '../input/'\n",
    "TRAIN_FILE_PATH = f'{INPUT_DIR}train.csv'\n",
    "TEST_FILE_PATH = f'{INPUT_DIR}test.csv'\n",
    "SAMPLE_SUBMISSION_FILE_PATH = f'{INPUT_DIR}sample_submission.csv'\n",
    "\n",
    "SUBMISSIONS_DIR = '../submissions/'\n",
    "\n",
    "EMBEDDINGS_DIR = f'{INPUT_DIR}embeddings/'\n",
    "EMBEDDINGS_FILE_PATH = f'{EMBEDDINGS_DIR}glove.840B.300d.txt'\n",
    "\n",
    "OUTPUT_DIR = '../output/'\n",
    "OUTPUT_LOGS_DIR = f'{OUTPUT_DIR}{MODEL_NAME}/logs/'\n",
    "OUTPUT_MODELS_DIR = f'{OUTPUT_DIR}{MODEL_NAME}/models/'\n",
    "OUTPUT_SUMMARIES_DIR = f'{OUTPUT_DIR}{MODEL_NAME}/summaries/'\n",
    "\n",
    "# Create the output directories if they do not exist (the `_` is necessary\n",
    "# in order to create intermediate directories and is itself not created)\n",
    "os.makedirs(os.path.dirname(f'{OUTPUT_LOGS_DIR}_'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(f'{OUTPUT_MODELS_DIR}_'), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(f'{OUTPUT_SUMMARIES_DIR}_'), exist_ok=True)\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "MAX_FEATURES = None # The top most common words if an integer; otherwise, all words are used\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "N_SPLITS = 10\n",
    "\n",
    "# Fix a random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, submission = load_data(TRAIN_FILE_PATH, \n",
    "                                    TEST_FILE_PATH, \n",
    "                                    SAMPLE_SUBMISSION_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25943 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Todo: Decide whether or not to perform custom text preprocessing beforehand\n",
    "# X_train_sequences = list(train['text'].apply(lambda x: process_text(x)).values)\n",
    "# X_test_sequences = list(test['text'].apply(lambda x: process_text(x)).values)\n",
    "X_train_sequences = list(train['text'].values)\n",
    "X_test_sequences = list(test['text'].values)\n",
    "\n",
    "# Tokenize and pad the sentences\n",
    "X_train_tokenized, X_test_tokenized, word_index = compute_word_index(X_train_sequences,\n",
    "                                                                     X_test_sequences,\n",
    "                                                                     MAX_FEATURES,\n",
    "                                                                     MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the embedding layer\n",
    "These results will later be used during stratified k-fold to construct the embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196017it [02:05, 17504.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196016 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = load_embeddings(EMBEDDINGS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vocabulary words not found in the pre-trained embeddings: 2761 of 25943 (10.64%)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix, vocab_size, num_unknown = construct_embedding_matrix(word_index, \n",
    "                                                                       embeddings_index, \n",
    "                                                                       EMBEDDING_DIM)\n",
    "# Here we subtract 1 from the vocab size because 1 has been added to the\n",
    "# actual number of tokens to account for masking in the embedding matrix\n",
    "unknown_word_percentage = (num_unknown / (vocab_size - 1)) * 100\n",
    "unknown_word_lines = ('Number of vocabulary words not found in the pre-trained embeddings: '\n",
    "                      f'{num_unknown} of {vocab_size - 1} '\n",
    "                      f'({unknown_word_percentage:.2f}%)')\n",
    "print(unknown_word_lines)\n",
    "preprocessing_file_path = f'{OUTPUT_LOGS_DIR}preprocessing.log.txt'\n",
    "save_line_to_file(unknown_word_lines, preprocessing_file_path, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "Each model will be evaluated based on the logloss metric using either 5-fold or 10-fold cross validation; the lower the logloss, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class labels: ['EAP' 'HPL' 'MWS']\n"
     ]
    }
   ],
   "source": [
    "# The target classes need to be converted to integers so that\n",
    "# EAP --> 0\n",
    "# HPL --> 1\n",
    "# MWS --> 2\n",
    "y_train_integers = integer_encode_classes(train['author'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target classes need to be one-hot encoded so that\n",
    "# EAP --> 0 --> [1, 0, 0]\n",
    "# HPL --> 1 --> [0, 1, 0]\n",
    "# MWS --> 2 --> [0, 0, 1]\n",
    "y_train_encoded = one_hot_encode_classes(y_train_integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model-dependent files\n",
    "from models import build_embedding_layer, build_model_callbacks, save_model_summary\n",
    "from models import build_random_cnn_model as build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Fold 1 of 10 -----\n",
      "Train on 17620 samples, validate on 1959 samples\n",
      "Epoch 1/100\n",
      "17620/17620 [==============================] - 23s 1ms/step - loss: 0.7664 - acc: 0.6593 - val_loss: 0.6309 - val_acc: 0.7310\n",
      "Epoch 2/100\n",
      "17620/17620 [==============================] - 9s 528us/step - loss: 0.6003 - acc: 0.7502 - val_loss: 0.5673 - val_acc: 0.7560\n",
      "Epoch 3/100\n",
      "17620/17620 [==============================] - 9s 528us/step - loss: 0.5146 - acc: 0.7904 - val_loss: 0.5260 - val_acc: 0.7754\n",
      "Epoch 4/100\n",
      "17620/17620 [==============================] - 9s 528us/step - loss: 0.4369 - acc: 0.8256 - val_loss: 0.5408 - val_acc: 0.7774\n",
      "Epoch 5/100\n",
      "17620/17620 [==============================] - 9s 522us/step - loss: 0.3764 - acc: 0.8514 - val_loss: 0.5096 - val_acc: 0.7963\n",
      "Epoch 6/100\n",
      "17620/17620 [==============================] - 9s 525us/step - loss: 0.3132 - acc: 0.8800 - val_loss: 0.4817 - val_acc: 0.8009\n",
      "Epoch 7/100\n",
      "17620/17620 [==============================] - 9s 529us/step - loss: 0.2558 - acc: 0.9052 - val_loss: 0.5197 - val_acc: 0.7912\n",
      "Epoch 8/100\n",
      "17620/17620 [==============================] - 9s 534us/step - loss: 0.1969 - acc: 0.9279 - val_loss: 0.5011 - val_acc: 0.8152\n",
      "Epoch 9/100\n",
      "17620/17620 [==============================] - 9s 530us/step - loss: 0.1619 - acc: 0.9423 - val_loss: 0.5545 - val_acc: 0.7928\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "----- Fold 2 of 10 -----\n",
      "Train on 17620 samples, validate on 1959 samples\n",
      "Epoch 1/100\n",
      "17620/17620 [==============================] - 23s 1ms/step - loss: 0.7614 - acc: 0.6627 - val_loss: 0.6270 - val_acc: 0.7427\n",
      "Epoch 2/100\n",
      "17620/17620 [==============================] - 9s 525us/step - loss: 0.6014 - acc: 0.7468 - val_loss: 0.5613 - val_acc: 0.7682\n",
      "Epoch 3/100\n",
      "17620/17620 [==============================] - 9s 528us/step - loss: 0.5229 - acc: 0.7879 - val_loss: 0.5171 - val_acc: 0.7861\n",
      "Epoch 4/100\n",
      "17620/17620 [==============================] - 9s 522us/step - loss: 0.4497 - acc: 0.8205 - val_loss: 0.4803 - val_acc: 0.8091\n",
      "Epoch 5/100\n",
      "17620/17620 [==============================] - 9s 523us/step - loss: 0.3892 - acc: 0.8444 - val_loss: 0.4751 - val_acc: 0.8101\n",
      "Epoch 6/100\n",
      "17620/17620 [==============================] - 9s 522us/step - loss: 0.3186 - acc: 0.8779 - val_loss: 0.4690 - val_acc: 0.8132\n",
      "Epoch 7/100\n",
      "17620/17620 [==============================] - 9s 526us/step - loss: 0.2654 - acc: 0.8996 - val_loss: 0.4664 - val_acc: 0.8173\n",
      "Epoch 8/100\n",
      "17620/17620 [==============================] - 9s 523us/step - loss: 0.2058 - acc: 0.9246 - val_loss: 0.5012 - val_acc: 0.8127\n",
      "Epoch 9/100\n",
      "17620/17620 [==============================] - 9s 525us/step - loss: 0.1709 - acc: 0.9390 - val_loss: 0.5168 - val_acc: 0.8137\n",
      "Epoch 10/100\n",
      "17620/17620 [==============================] - 9s 525us/step - loss: 0.1316 - acc: 0.9540 - val_loss: 0.5099 - val_acc: 0.8229\n",
      "Epoch 00010: early stopping\n",
      "\n",
      "----- Fold 3 of 10 -----\n",
      "Train on 17620 samples, validate on 1959 samples\n",
      "Epoch 1/100\n",
      "17620/17620 [==============================] - 23s 1ms/step - loss: 0.7621 - acc: 0.6619 - val_loss: 0.6545 - val_acc: 0.7300\n",
      "Epoch 2/100\n",
      "17620/17620 [==============================] - 9s 528us/step - loss: 0.5920 - acc: 0.7548 - val_loss: 0.5851 - val_acc: 0.7575\n",
      "Epoch 3/100\n",
      "17620/17620 [==============================] - 9s 525us/step - loss: 0.5096 - acc: 0.7911 - val_loss: 0.5414 - val_acc: 0.7805\n",
      "Epoch 4/100\n",
      "17620/17620 [==============================] - 9s 524us/step - loss: 0.4396 - acc: 0.8230 - val_loss: 0.5668 - val_acc: 0.7642\n",
      "Epoch 5/100\n",
      "17620/17620 [==============================] - 9s 520us/step - loss: 0.3746 - acc: 0.8546 - val_loss: 0.5413 - val_acc: 0.7846\n",
      "Epoch 6/100\n",
      "17620/17620 [==============================] - 9s 525us/step - loss: 0.3111 - acc: 0.8812 - val_loss: 0.5206 - val_acc: 0.7948\n",
      "Epoch 7/100\n",
      "17620/17620 [==============================] - 9s 523us/step - loss: 0.2507 - acc: 0.9068 - val_loss: 0.5435 - val_acc: 0.7907\n",
      "Epoch 8/100\n",
      "17620/17620 [==============================] - 9s 523us/step - loss: 0.2088 - acc: 0.9238 - val_loss: 0.5489 - val_acc: 0.8025\n",
      "Epoch 9/100\n",
      "17620/17620 [==============================] - 9s 529us/step - loss: 0.1552 - acc: 0.9453 - val_loss: 0.5926 - val_acc: 0.7984\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "----- Fold 4 of 10 -----\n",
      "Train on 17620 samples, validate on 1959 samples\n",
      "Epoch 1/100\n",
      "17620/17620 [==============================] - 23s 1ms/step - loss: 0.7569 - acc: 0.6656 - val_loss: 0.6255 - val_acc: 0.7351\n",
      "Epoch 2/100\n",
      "17620/17620 [==============================] - 9s 533us/step - loss: 0.5956 - acc: 0.7515 - val_loss: 0.5462 - val_acc: 0.7723\n",
      "Epoch 3/100\n",
      "17620/17620 [==============================] - 9s 537us/step - loss: 0.5154 - acc: 0.7916 - val_loss: 0.5047 - val_acc: 0.7933\n",
      "Epoch 4/100\n",
      "17620/17620 [==============================] - 9s 518us/step - loss: 0.4464 - acc: 0.8211 - val_loss: 0.4920 - val_acc: 0.7948\n",
      "Epoch 5/100\n",
      "17620/17620 [==============================] - 9s 520us/step - loss: 0.3759 - acc: 0.8516 - val_loss: 0.4531 - val_acc: 0.8127\n",
      "Epoch 6/100\n",
      "17620/17620 [==============================] - 9s 515us/step - loss: 0.3154 - acc: 0.8788 - val_loss: 0.4532 - val_acc: 0.8101\n",
      "Epoch 7/100\n",
      "17620/17620 [==============================] - 9s 519us/step - loss: 0.2527 - acc: 0.9072 - val_loss: 0.4742 - val_acc: 0.8070\n",
      "Epoch 8/100\n",
      "17620/17620 [==============================] - 9s 518us/step - loss: 0.2049 - acc: 0.9242 - val_loss: 0.4808 - val_acc: 0.8218\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "----- Fold 5 of 10 -----\n",
      "Train on 17621 samples, validate on 1958 samples\n",
      "Epoch 1/100\n",
      "17621/17621 [==============================] - 23s 1ms/step - loss: 0.7661 - acc: 0.6605 - val_loss: 0.6103 - val_acc: 0.7508\n",
      "Epoch 2/100\n",
      "17621/17621 [==============================] - 9s 514us/step - loss: 0.6109 - acc: 0.7466 - val_loss: 0.5417 - val_acc: 0.7748\n",
      "Epoch 3/100\n",
      "17621/17621 [==============================] - 9s 517us/step - loss: 0.5176 - acc: 0.7894 - val_loss: 0.5179 - val_acc: 0.7891\n",
      "Epoch 4/100\n",
      "17621/17621 [==============================] - 9s 521us/step - loss: 0.4470 - acc: 0.8195 - val_loss: 0.4612 - val_acc: 0.8090\n",
      "Epoch 5/100\n",
      "17621/17621 [==============================] - 9s 514us/step - loss: 0.3851 - acc: 0.8481 - val_loss: 0.5091 - val_acc: 0.7978\n",
      "Epoch 6/100\n",
      "17621/17621 [==============================] - 9s 517us/step - loss: 0.3225 - acc: 0.8758 - val_loss: 0.4457 - val_acc: 0.8172\n",
      "Epoch 7/100\n",
      "17621/17621 [==============================] - 9s 517us/step - loss: 0.2565 - acc: 0.9036 - val_loss: 0.4961 - val_acc: 0.8187\n",
      "Epoch 8/100\n",
      "17621/17621 [==============================] - 9s 513us/step - loss: 0.2106 - acc: 0.9223 - val_loss: 0.4647 - val_acc: 0.8202\n",
      "Epoch 9/100\n",
      "17621/17621 [==============================] - 9s 518us/step - loss: 0.1616 - acc: 0.9421 - val_loss: 0.4793 - val_acc: 0.8289\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "----- Fold 6 of 10 -----\n",
      "Train on 17622 samples, validate on 1957 samples\n",
      "Epoch 1/100\n",
      "17622/17622 [==============================] - 23s 1ms/step - loss: 0.7661 - acc: 0.6607 - val_loss: 0.6402 - val_acc: 0.7307\n",
      "Epoch 2/100\n",
      "17622/17622 [==============================] - 9s 521us/step - loss: 0.5989 - acc: 0.7508 - val_loss: 0.5729 - val_acc: 0.7670\n",
      "Epoch 3/100\n",
      "17622/17622 [==============================] - 9s 514us/step - loss: 0.5119 - acc: 0.7914 - val_loss: 0.5492 - val_acc: 0.7793\n",
      "Epoch 4/100\n",
      "17622/17622 [==============================] - 9s 520us/step - loss: 0.4375 - acc: 0.8259 - val_loss: 0.5375 - val_acc: 0.7966\n",
      "Epoch 5/100\n",
      "17622/17622 [==============================] - 9s 516us/step - loss: 0.3674 - acc: 0.8550 - val_loss: 0.5234 - val_acc: 0.7971\n",
      "Epoch 6/100\n",
      "17622/17622 [==============================] - 9s 520us/step - loss: 0.3062 - acc: 0.8826 - val_loss: 0.5553 - val_acc: 0.7920\n",
      "Epoch 7/100\n",
      "17622/17622 [==============================] - 9s 516us/step - loss: 0.2510 - acc: 0.9043 - val_loss: 0.5708 - val_acc: 0.7931\n",
      "Epoch 8/100\n",
      "17622/17622 [==============================] - 9s 515us/step - loss: 0.2012 - acc: 0.9262 - val_loss: 0.5634 - val_acc: 0.7910\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "----- Fold 7 of 10 -----\n",
      "Train on 17622 samples, validate on 1957 samples\n",
      "Epoch 1/100\n",
      "17622/17622 [==============================] - 23s 1ms/step - loss: 0.7650 - acc: 0.6618 - val_loss: 0.6326 - val_acc: 0.7307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "17622/17622 [==============================] - 9s 520us/step - loss: 0.5965 - acc: 0.7512 - val_loss: 0.5760 - val_acc: 0.7629\n",
      "Epoch 3/100\n",
      "17622/17622 [==============================] - 9s 520us/step - loss: 0.5167 - acc: 0.7876 - val_loss: 0.5561 - val_acc: 0.7685\n",
      "Epoch 4/100\n",
      "17622/17622 [==============================] - 9s 516us/step - loss: 0.4471 - acc: 0.8210 - val_loss: 0.5162 - val_acc: 0.7869\n",
      "Epoch 5/100\n",
      "17622/17622 [==============================] - 9s 520us/step - loss: 0.3766 - acc: 0.8536 - val_loss: 0.5179 - val_acc: 0.7920\n",
      "Epoch 6/100\n",
      "17622/17622 [==============================] - 9s 520us/step - loss: 0.3115 - acc: 0.8801 - val_loss: 0.4947 - val_acc: 0.8063\n",
      "Epoch 7/100\n",
      "17622/17622 [==============================] - 9s 522us/step - loss: 0.2593 - acc: 0.9056 - val_loss: 0.5105 - val_acc: 0.8028\n",
      "Epoch 8/100\n",
      "17622/17622 [==============================] - 9s 520us/step - loss: 0.1975 - acc: 0.9290 - val_loss: 0.5325 - val_acc: 0.8028\n",
      "Epoch 9/100\n",
      "17622/17622 [==============================] - 9s 522us/step - loss: 0.1562 - acc: 0.9436 - val_loss: 0.5612 - val_acc: 0.8068\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "----- Fold 8 of 10 -----\n",
      "Train on 17622 samples, validate on 1957 samples\n",
      "Epoch 1/100\n",
      "17622/17622 [==============================] - 24s 1ms/step - loss: 0.7536 - acc: 0.6673 - val_loss: 0.6037 - val_acc: 0.7368\n",
      "Epoch 2/100\n",
      "17622/17622 [==============================] - 9s 536us/step - loss: 0.5973 - acc: 0.7480 - val_loss: 0.5498 - val_acc: 0.7655\n",
      "Epoch 3/100\n",
      "17622/17622 [==============================] - 10s 540us/step - loss: 0.5159 - acc: 0.7912 - val_loss: 0.4926 - val_acc: 0.7920\n",
      "Epoch 4/100\n",
      "17622/17622 [==============================] - 9s 530us/step - loss: 0.4439 - acc: 0.8186 - val_loss: 0.4640 - val_acc: 0.8114\n",
      "Epoch 5/100\n",
      "17622/17622 [==============================] - 9s 529us/step - loss: 0.3755 - acc: 0.8517 - val_loss: 0.4650 - val_acc: 0.8084\n",
      "Epoch 6/100\n",
      "17622/17622 [==============================] - 9s 526us/step - loss: 0.3177 - acc: 0.8784 - val_loss: 0.4778 - val_acc: 0.8063\n",
      "Epoch 7/100\n",
      "17622/17622 [==============================] - 9s 527us/step - loss: 0.2547 - acc: 0.9049 - val_loss: 0.4910 - val_acc: 0.8084\n",
      "Epoch 00007: early stopping\n",
      "\n",
      "----- Fold 9 of 10 -----\n",
      "Train on 17622 samples, validate on 1957 samples\n",
      "Epoch 1/100\n",
      "17622/17622 [==============================] - 24s 1ms/step - loss: 0.7608 - acc: 0.6638 - val_loss: 0.6585 - val_acc: 0.7251\n",
      "Epoch 2/100\n",
      "17622/17622 [==============================] - 9s 532us/step - loss: 0.5972 - acc: 0.7517 - val_loss: 0.5902 - val_acc: 0.7603\n",
      "Epoch 3/100\n",
      "17622/17622 [==============================] - 9s 534us/step - loss: 0.5109 - acc: 0.7920 - val_loss: 0.5652 - val_acc: 0.7721\n",
      "Epoch 4/100\n",
      "17622/17622 [==============================] - 10s 539us/step - loss: 0.4385 - acc: 0.8257 - val_loss: 0.5170 - val_acc: 0.7920\n",
      "Epoch 5/100\n",
      "17622/17622 [==============================] - 10s 551us/step - loss: 0.3735 - acc: 0.8535 - val_loss: 0.5548 - val_acc: 0.7828\n",
      "Epoch 6/100\n",
      "17622/17622 [==============================] - 10s 553us/step - loss: 0.3118 - acc: 0.8812 - val_loss: 0.5034 - val_acc: 0.7976\n",
      "Epoch 7/100\n",
      "17622/17622 [==============================] - 10s 543us/step - loss: 0.2512 - acc: 0.9047 - val_loss: 0.5340 - val_acc: 0.8068\n",
      "Epoch 8/100\n",
      "17622/17622 [==============================] - 9s 536us/step - loss: 0.2040 - acc: 0.9258 - val_loss: 0.5377 - val_acc: 0.8007\n",
      "Epoch 9/100\n",
      "17622/17622 [==============================] - 9s 536us/step - loss: 0.1550 - acc: 0.9451 - val_loss: 0.5770 - val_acc: 0.7971\n",
      "Epoch 00009: early stopping\n",
      "\n",
      "----- Fold 10 of 10 -----\n",
      "Train on 17622 samples, validate on 1957 samples\n",
      "Epoch 1/100\n",
      "17622/17622 [==============================] - 24s 1ms/step - loss: 0.7635 - acc: 0.6638 - val_loss: 0.6483 - val_acc: 0.7251\n",
      "Epoch 2/100\n",
      "17622/17622 [==============================] - 10s 539us/step - loss: 0.5970 - acc: 0.7522 - val_loss: 0.5470 - val_acc: 0.7808\n",
      "Epoch 3/100\n",
      "17622/17622 [==============================] - 10s 545us/step - loss: 0.5093 - acc: 0.7907 - val_loss: 0.5256 - val_acc: 0.7726\n",
      "Epoch 4/100\n",
      "17622/17622 [==============================] - 10s 540us/step - loss: 0.4311 - acc: 0.8289 - val_loss: 0.5124 - val_acc: 0.7920\n",
      "Epoch 5/100\n",
      "17622/17622 [==============================] - 10s 541us/step - loss: 0.3685 - acc: 0.8561 - val_loss: 0.4796 - val_acc: 0.8048\n",
      "Epoch 6/100\n",
      "17622/17622 [==============================] - 9s 535us/step - loss: 0.3068 - acc: 0.8796 - val_loss: 0.5008 - val_acc: 0.8053\n",
      "Epoch 7/100\n",
      "17622/17622 [==============================] - 10s 539us/step - loss: 0.2432 - acc: 0.9085 - val_loss: 0.4991 - val_acc: 0.8063\n",
      "Epoch 8/100\n",
      "17622/17622 [==============================] - 9s 528us/step - loss: 0.1993 - acc: 0.9276 - val_loss: 0.5175 - val_acc: 0.8058\n",
      "Epoch 00008: early stopping\n",
      "Writing runtime log to file...\n",
      "Writing CV results summary to file...\n"
     ]
    }
   ],
   "source": [
    "training_num_epochs = 100\n",
    "batch_size = 64 # 32, 64, 128, 256, 512\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "folds = kfold.split(X_train_tokenized, y_train_integers)\n",
    "\n",
    "monitored_metric = 'val_loss'\n",
    "other_metrics = ['val_acc', 'loss', 'acc']\n",
    "all_metrics = ['val_loss', 'val_acc', 'loss', 'acc']\n",
    "all_scores = {\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'loss': [],\n",
    "    'acc': [],\n",
    "}\n",
    "best_scores_per_fold = {\n",
    "    'val_loss': [],\n",
    "    'val_acc': [],\n",
    "    'loss': [],\n",
    "    'acc': [],\n",
    "}\n",
    "# The number of training epochs that have passed at which\n",
    "# the best validation loss is recorded\n",
    "best_score_num_epochs = []\n",
    "# Runtime records\n",
    "pred_runtimes = []\n",
    "pred_runtime_strs = []\n",
    "training_start = time()\n",
    "\n",
    "for fold, (train_indices, valid_indices) in enumerate(folds):\n",
    "    # Print the current fold\n",
    "    nth_fold = fold + 1\n",
    "    nth_fold_str = f'fold_{nth_fold:02d}'\n",
    "    print(f'\\n----- Fold {nth_fold} of {N_SPLITS} -----')\n",
    "    \n",
    "    # Prepare the splits of data\n",
    "    X_train, y_train = X_train_tokenized[train_indices], y_train_encoded[train_indices]\n",
    "    X_valid, y_valid = X_train_tokenized[valid_indices], y_train_encoded[valid_indices]\n",
    "    \n",
    "    # Build the embedding layer\n",
    "    embedding_layer = build_embedding_layer(embedding_matrix, \n",
    "                                            vocab_size, \n",
    "                                            EMBEDDING_DIM, \n",
    "                                            MAX_SEQUENCE_LENGTH)\n",
    "    # Construct model callbacks, save the best models, and log metrics to file\n",
    "    progress_file_path = f'{OUTPUT_LOGS_DIR}metric_progress.log.txt'\n",
    "    model_file_path = f'{OUTPUT_MODELS_DIR}{nth_fold_str}.model.hdf5'\n",
    "    logger_file_path = f'{OUTPUT_LOGS_DIR}{nth_fold_str}.log.csv'\n",
    "    model_callbacks = build_model_callbacks(monitored_metric,\n",
    "                                            'min',\n",
    "                                            progress_file_path,\n",
    "                                            model_file_path,\n",
    "                                            logger_file_path,\n",
    "                                            nth_fold,\n",
    "                                            N_SPLITS)\n",
    "    # Build the model\n",
    "    model = build_model(embedding_layer, MAX_SEQUENCE_LENGTH)    \n",
    "    # Save the model summary to file on the first fold only\n",
    "    # since the models are identical across folds\n",
    "    if nth_fold == 1:\n",
    "        save_model_summary(model, f'{OUTPUT_SUMMARIES_DIR}cv.model_summary.txt')\n",
    "    # Train the model\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=training_num_epochs,\n",
    "                        verbose=1,\n",
    "                        callbacks=model_callbacks,\n",
    "                        validation_data=[X_valid, y_valid],\n",
    "                        shuffle=True)\n",
    "    \n",
    "    # Save the scores for later evaluation\n",
    "    monitored_metric_fold_scores = history.history[monitored_metric]\n",
    "    all_scores[monitored_metric].append(monitored_metric_fold_scores)\n",
    "    # Save only the best validation loss\n",
    "    epoch_index = np.argmin(monitored_metric_fold_scores)\n",
    "    best_score_num_epochs.append(epoch_index + 1)\n",
    "    best_monitored_metric_score = monitored_metric_fold_scores[epoch_index]\n",
    "    best_scores_per_fold[monitored_metric].append(best_monitored_metric_score)\n",
    "    \n",
    "    for metric in other_metrics:\n",
    "        other_metric_fold_scores = history.history[metric]\n",
    "        all_scores[metric].append(other_metric_fold_scores)\n",
    "        # Save only the corresponding current metric score for the\n",
    "        # best validation loss epoch\n",
    "        same_epoch_score = other_metric_fold_scores[epoch_index]\n",
    "        best_scores_per_fold[metric].append(same_epoch_score)\n",
    "        \n",
    "    # Display a classification report and confusion matrix\n",
    "    print('Making predictions...')\n",
    "    pred_start = time()\n",
    "    y_pred = model.predict(X_valid, batch_size=batch_size, verbose=0)\n",
    "    pred_elapsed, pred_elapsed_str = get_time_elapsed(pred_start)\n",
    "    pred_runtimes.append(pred_elapsed)\n",
    "    pred_runtime_strs.append(pred_elapsed_str)\n",
    "    \n",
    "    print('Writing classification summary to file...')\n",
    "    classification_file_path = (f'{OUTPUT_SUMMARIES_DIR}'\n",
    "                                f'{nth_fold_str}.class_summary.txt')\n",
    "    save_classification_summary(y_valid,\n",
    "                                y_pred,\n",
    "                                [0, 1, 2],\n",
    "                                ['EAP', 'HPL', 'MWS'],\n",
    "                                classification_file_path)\n",
    "\n",
    "print('Writing runtime log to file...')\n",
    "training_elapsed, training_elapsed_str = get_time_elapsed(training_start)\n",
    "training_fold_elapsed_str = format_time_str(training_elapsed / N_SPLITS)\n",
    "pred_elapsed = np.sum(pred_runtimes)\n",
    "pred_elapsed_str = format_time_str(pred_elapsed)\n",
    "pred_fold_elapsed_str = format_time_str(pred_elapsed / N_SPLITS)\n",
    "runtime_lines = (f'Total stratified {N_SPLITS}-fold loop runtime: {training_elapsed_str}\\n'\n",
    "                 f'Average training runtime per fold: {training_fold_elapsed_str}\\n\\n'\n",
    "                 f'Total stratified {N_SPLITS}-fold prediction runtime: {pred_elapsed_str}\\n'\n",
    "                 f'Average prediction runtime per fold: {pred_fold_elapsed_str}\\n\\n')\n",
    "for f, time_str in enumerate(pred_runtime_strs):\n",
    "    runtime_lines += f'Fold {f + 1} prediction runtime: {time_str}\\n'\n",
    "runtime_file_path = f'{OUTPUT_LOGS_DIR}runtime.log.txt'\n",
    "save_line_to_file(runtime_lines, runtime_file_path, 'w')\n",
    "\n",
    "# Calculate the mean and standard deviation across all folds' best scores\n",
    "print('Writing CV results summary to file...')\n",
    "summary_lines = 'CV Results Summary:\\n'\n",
    "for metric in all_metrics:\n",
    "    mean = np.mean(best_scores_per_fold[metric])\n",
    "    std = np.std(best_scores_per_fold[metric])\n",
    "    summary_lines += f'- {metric} mean and std: {mean:.5f} (+/- {std:.5f})\\n'\n",
    "monitored_mean = np.mean(best_scores_per_fold[monitored_metric])\n",
    "summary_file_path = f'{OUTPUT_SUMMARIES_DIR}{monitored_mean:.5f}.results_summary.txt'\n",
    "save_line_to_file(summary_lines, summary_file_path, 'w')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Example:\\n{\\n    'val_loss': [[0.8656108248708684, 0.8480148858142459], # Fold 1, scores per epoch\\n    [0.8535823000075321, 0.8520218395263746]], # Fold 2, scores per epoch\\n\\n    'val_acc': [[0.6107252297776469, 0.6267620020916075],\\n    [0.6173255694620041, 0.6308100929066869]],\\n\\n    'loss': [[0.9227827079133659, 0.6396668943775261],\\n    [0.9183809885209135, 0.636743621745806]],\\n\\n    'acc': [[0.5735008681389172, 0.7408315457037562],\\n    [0.5728294178462978, 0.7402451480737867]]\\n}\\n\""
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: There might be a different number of epochs per fold\n",
    "\"\"\" Example:\n",
    "{\n",
    "    'val_loss': [[0.8656108248708684, 0.8480148858142459], # Fold 1, scores per epoch\n",
    "    [0.8535823000075321, 0.8520218395263746]], # Fold 2, scores per epoch\n",
    "\n",
    "    'val_acc': [[0.6107252297776469, 0.6267620020916075],\n",
    "    [0.6173255694620041, 0.6308100929066869]],\n",
    "\n",
    "    'loss': [[0.9227827079133659, 0.6396668943775261],\n",
    "    [0.9183809885209135, 0.636743621745806]],\n",
    "\n",
    "    'acc': [[0.5735008681389172, 0.7408315457037562],\n",
    "    [0.5728294178462978, 0.7402451480737867]]\n",
    "}\n",
    "\"\"\"\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 6, 6, 8, 6, 7, 7, 7, 6]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pass in a metric (without the `val_` prefix) and a fold index to show\n",
    "# the training and validation error curves over the number of epochs\n",
    "display_metric_vs_epochs_plot(all_scores, 'loss', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_metric_vs_epochs_plot(all_scores, 'acc', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on the test data\n",
    "In order to make predictions on the Kaggle-provided unlabeled test data, we will need to submit our predictions to Kaggle. It would be best to train on the entire training set; this means that, this time, we won't provide a validation set to the Keras model.\n",
    "\n",
    "How do we know how many epochs to train for? To figure this out, we can use the results from the cross validation phase. Since we have recorded the number of epochs that each fold took to train the model before stopping, we can take the average number of epochs across all folds and use that as the number of epochs to train our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the number of epochs to train for using the entire training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score_num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take the average number of epochs across all folds.\n",
    "final_num_epochs = np.mean(best_score_num_epochs)\n",
    "# We take the ceiling because it's better to train for a little longer than to underfit.\n",
    "final_num_epochs = np.ceil(final_num_epochs)\n",
    "# We need to cast it to an int before feeding it to `model.fit`.\n",
    "final_num_epochs = int(final_num_epochs)\n",
    "final_num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import build_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the embedding layer\n",
    "embedding_layer = build_embedding_layer(embedding_matrix, \n",
    "                                        vocab_size, \n",
    "                                        EMBEDDING_DIM, \n",
    "                                        MAX_SEQUENCE_LENGTH)\n",
    "# Build the model\n",
    "model = build_cnn_model(embedding_layer, MAX_SEQUENCE_LENGTH)\n",
    "# Save the model architecture, weights, and optimizer state to file\n",
    "model.save(f'{OUTPUT_MODELS_DIR}final.model.hdf5')\n",
    "# Save the model summary to file\n",
    "save_model_summary(model, f'{OUTPUT_SUMMARIES_DIR}final.model_summary.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19579/19579 [==============================] - 26s 1ms/step - loss: 0.8842 - acc: 0.5964\n",
      "Epoch 2/2\n",
      "19579/19579 [==============================] - 27s 1ms/step - loss: 0.6554 - acc: 0.7255\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_tokenized,\n",
    "                    y_train_encoded,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=final_num_epochs,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8392/8392 [==============================] - 5s 619us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_tokenized, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03579558, 0.01009183, 0.9541125 ],\n",
       "       [0.93095404, 0.06735893, 0.00168709],\n",
       "       [0.00521636, 0.9862598 , 0.00852381]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the final submission values\n",
    "predictions[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[['EAP', 'HPL', 'MWS']] = predictions\n",
    "submission.to_csv(f'{SUBMISSIONS_DIR}001_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the average logloss of the Kaggle submission\n",
    "After submitting to Kaggle, we can calculate the average logloss across the entire test dataset as follows:\n",
    "```\n",
    "Given:\n",
    "    n_test = 8392\n",
    "    %_private = 0.7\n",
    "    %_public = 0.3\n",
    "Average logloss = (private_logloss * n_private + public_logloss * n_public) / n_test\n",
    "                = (private_logloss * (%_private * n_test)\n",
    "                  + public_logloss * (%_public * n_test))\n",
    "                  / n_test\n",
    "Where n_test = n_private + n_public\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinement\n",
    "Run random search to tune certain hyperparameters for each algorithm for at least 60 iterations (but Ill lower that number if it ends up taking way too long) in order to find the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "authorid-test",
   "language": "python",
   "name": "authorid-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
